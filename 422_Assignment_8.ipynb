{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "422 - Assignment 8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ2S8qMdBjyM",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "56826d6e-dd4d-4b1f-8e79-93b113e8d23b",
        "id": "IQVCfgmMDq6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# Python chakin package install\n",
        "!pip install chakin\n",
        "\n",
        "# Common imports for our work\n",
        "import os, time, re, cv2, chakin, json\n",
        "import pandas as pd  # data frame operations  \n",
        "import numpy as np  # arrays and math functions\n",
        "import matplotlib.pyplot as plt  # static plotting\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import tensorflow as tf\n",
        "import scipy, sklearn\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from datetime import datetime\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chakin\n",
            "  Downloading https://files.pythonhosted.org/packages/ca/3f/ca2f63451c0ab47970a6ab1d39d96118e70b6e73125529cea767c31368a3/chakin-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.20.1 in /usr/local/lib/python3.6/dist-packages (from chakin) (0.25.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from chakin) (1.12.0)\n",
            "Requirement already satisfied: progressbar2>=3.20.0 in /usr/local/lib/python3.6/dist-packages (from chakin) (3.38.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (1.17.5)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2>=3.20.0->chakin) (2.3.0)\n",
            "Installing collected packages: chakin\n",
            "Successfully installed chakin-0.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4lC_VK562av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K96CUcgBwzA",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Download GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGMEUayTERJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "fdd661bd-4e5c-43ed-8d56-9b7cb5f2fa19"
      },
      "source": [
        "chakin.search(lang='English')  # lists available indices in English"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   Name  Dimension  ... Language    Author\n",
            "2          fastText(en)        300  ...  English  Facebook\n",
            "11         GloVe.6B.50d         50  ...  English  Stanford\n",
            "12        GloVe.6B.100d        100  ...  English  Stanford\n",
            "13        GloVe.6B.200d        200  ...  English  Stanford\n",
            "14        GloVe.6B.300d        300  ...  English  Stanford\n",
            "15       GloVe.42B.300d        300  ...  English  Stanford\n",
            "16      GloVe.840B.300d        300  ...  English  Stanford\n",
            "17    GloVe.Twitter.25d         25  ...  English  Stanford\n",
            "18    GloVe.Twitter.50d         50  ...  English  Stanford\n",
            "19   GloVe.Twitter.100d        100  ...  English  Stanford\n",
            "20   GloVe.Twitter.200d        200  ...  English  Stanford\n",
            "21  word2vec.GoogleNews        300  ...  English    Google\n",
            "\n",
            "[12 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiTQdZCSEqsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify English embeddings file to download and install by index number, number of dimensions, and subfoder name\n",
        "# Note that GloVe 50-, 100-, 200-, and 300-dimensional folders are downloaded with a single zip download\n",
        "CHAKIN_INDEX = 11\n",
        "NUMBER_OF_DIMENSIONS = 50\n",
        "SUBFOLDER_NAME = \"gloVe.6B\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yizqbSOhEx3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_FOLDER = \"embeddings\"\n",
        "ZIP_FILE = os.path.join(DATA_FOLDER, \"{}.zip\".format(SUBFOLDER_NAME))\n",
        "ZIP_FILE_ALT = \"glove\" + ZIP_FILE[5:]  # sometimes it's lowercase only...\n",
        "UNZIP_FOLDER = os.path.join(DATA_FOLDER, SUBFOLDER_NAME)\n",
        "if SUBFOLDER_NAME[-1] == \"d\":\n",
        "    GLOVE_FILENAME = os.path.join(\n",
        "        UNZIP_FOLDER, \"{}.txt\".format(SUBFOLDER_NAME))\n",
        "else:\n",
        "    GLOVE_FILENAME = os.path.join(UNZIP_FOLDER, \"{}.{}d.txt\".format(\n",
        "        SUBFOLDER_NAME, NUMBER_OF_DIMENSIONS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUrsOzzPKz4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "19859ca2-72e2-4822-f22d-0646251b760b"
      },
      "source": [
        "# download zip\n",
        "if not os.path.exists(ZIP_FILE) and not os.path.exists(UNZIP_FOLDER):\n",
        "    print(\"Downloading embeddings to '{}'\".format(ZIP_FILE))\n",
        "    chakin.download(number=CHAKIN_INDEX, save_dir='./{}'.format(DATA_FOLDER))\n",
        "else:\n",
        "    print(\"Embeddings already downloaded.\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading embeddings to 'embeddings/gloVe.6B.zip'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test: 100% ||                                      | Time:  0:06:27   2.1 MiB/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvpmR4HKXQej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "986e0b7e-53e1-4d74-9673-d2ccadb2e22d"
      },
      "source": [
        "print(os.path.join('/embeddings/', 'glove.6B.zip'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/embeddings/glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtzjlGtZQI-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e10e8739-ef39-47b5-e02c-58a07555ed3e"
      },
      "source": [
        "# unzip file\n",
        "if not os.path.exists(UNZIP_FOLDER):\n",
        "    import zipfile\n",
        "    if not os.path.exists(ZIP_FILE) and os.path.exists(ZIP_FILE_ALT):\n",
        "        ZIP_FILE = ZIP_FILE_ALT\n",
        "    with zipfile.ZipFile(\"embeddings/glove.6B.zip\", \"r\") as zip_ref:\n",
        "        print(\"Extracting embeddings to '{}'\".format(UNZIP_FOLDER))\n",
        "        zip_ref.extractall(UNZIP_FOLDER)\n",
        "else:\n",
        "    print(\"Embeddings already extracted.\")\n",
        "\n",
        "print('\\nRun complete')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting embeddings to 'embeddings/gloVe.6B'\n",
            "\n",
            "Run complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lLy2hpvYnzI",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Read Movie Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wH0s4KPY8Zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9ce0af0-6d05-4be8-84ae-b70afc66717a"
      },
      "source": [
        "# Common imports for our work\n",
        "from __future__ import absolute_import # from __future__ import absolute_import\n",
        "from __future__ import division # Changing the Division Operator\n",
        "from __future__ import print_function #Make print a function\n",
        "\n",
        "# Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "import numpy as np # import numpy\n",
        "import os  # operating system functions\n",
        "import os.path  # for manipulation of file path names\n",
        "import re  # regular expressions\n",
        "from collections import defaultdict # dict subclass that calls a factory function to supply missing values\n",
        "\n",
        "import nltk # Natural Language Toolkit\n",
        "from nltk.tokenize import TreebankWordTokenizer #tokenize text\n",
        "\n",
        "\n",
        "## Plot\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "# Other\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import tensorflow as tf #TensorFlow\n",
        "import time # Record processing time"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0Tbq8hZY-DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REMOVE_STOPWORDS = False  # no stopword removal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gqxi1oldTa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seed value for random number generators to obtain reproducible results\n",
        "RANDOM_SEED = 9999"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GGqwwKke820",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EVOCABSIZE = 10000  # specify desired size of pre-defined embedding vocabulary "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG7kwc_ZfALO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ------------------------------------------------------------- \n",
        "# Select the pre-defined embeddings source        \n",
        "# Define vocabulary size for the language model    \n",
        "# Create a word_to_embedding_dict for GloVe.6B.50d\n",
        "embeddings_directory = 'embeddings/gloVe.6B'\n",
        "filename = 'glove.6B.50d.txt'\n",
        "embeddings_filename = os.path.join(embeddings_directory, filename)\n",
        "# ------------------------------------------------------------- "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefjGHgqfHqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a embedding text file\n",
        "def load_embedding_from_disks(embeddings_filename, with_indexes=True):\n",
        "    \"\"\"\n",
        "    Read a embeddings txt file. If `with_indexes=True`, we return a tuple of two dictionaries \n",
        "    `(word_to_index_dict, index_to_embedding_array)`, otherwise we return only a direct \n",
        "    `word_to_embedding_dict` dictionary mapping from a string to a numpy array.\n",
        "    \"\"\"\n",
        "    if with_indexes:\n",
        "        word_to_index_dict = dict()\n",
        "        index_to_embedding_array = []\n",
        "  \n",
        "    else:\n",
        "        word_to_embedding_dict = dict()\n",
        "\n",
        "    with open(embeddings_filename, 'r', encoding='utf-8') as embeddings_file:\n",
        "        for (i, line) in enumerate(embeddings_file):\n",
        "\n",
        "            split = line.split(' ')\n",
        "\n",
        "            word = split[0]\n",
        "\n",
        "            representation = split[1:]\n",
        "            representation = np.array(\n",
        "                [float(val) for val in representation]\n",
        "            )\n",
        "\n",
        "            if with_indexes:\n",
        "                word_to_index_dict[word] = i\n",
        "                index_to_embedding_array.append(representation)\n",
        "            else:\n",
        "                word_to_embedding_dict[word] = representation\n",
        "\n",
        "    # Empty representation for unknown words.\n",
        "    _WORD_NOT_FOUND = [0.0] * len(representation)\n",
        "    if with_indexes:\n",
        "        _LAST_INDEX = i + 1\n",
        "        word_to_index_dict = defaultdict(\n",
        "            lambda: _LAST_INDEX, word_to_index_dict)\n",
        "        index_to_embedding_array = np.array(\n",
        "            index_to_embedding_array + [_WORD_NOT_FOUND])\n",
        "        return word_to_index_dict, index_to_embedding_array\n",
        "    else:\n",
        "        word_to_embedding_dict = defaultdict(lambda: _WORD_NOT_FOUND)\n",
        "        return word_to_embedding_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oZ3eOr4fKrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c59b0a98-8966-47b3-d165-ef94ea779bf5"
      },
      "source": [
        "# Check if the loaded embedding files glove.6B.50d. successfully.   \"glove.6B.50d.\"was ontained though \"run-chakin-to-get-embeddings-v001.py\"\n",
        "print('\\nLoading embeddings from', embeddings_filename)\n",
        "word_to_index, index_to_embedding = \\\n",
        "    load_embedding_from_disks(embeddings_filename, with_indexes=True)\n",
        "print(\"Embedding loaded from disks.\")\n",
        "\n",
        "# Note: unknown words have representations with values [0, 0, ..., 0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading embeddings from embeddings/gloVe.6B/glove.6B.50d.txt\n",
            "Embedding loaded from disks.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQbWLipTfZCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a1326e9e-728f-4faf-9c74-e6d9b111fecf"
      },
      "source": [
        "# Additional background code from\n",
        "# https://github.com/guillaume-chevalier/GloVe-as-a-TensorFlow-Embedding-Layer\n",
        "# shows the general structure of the data structures for word embeddings\n",
        "# This code is modified for our purposes in language modeling \n",
        "\n",
        "# Check vocabrary size and embedding dimention\n",
        "vocab_size, embedding_dim = index_to_embedding.shape\n",
        "print(\"Embedding is of shape: {}\".format(index_to_embedding.shape))\n",
        "print(\"This means (number of words, number of dimensions per word)\\n\")\n",
        "print(\"The first words are words that tend occur more often.\")\n",
        "\n",
        "#Check embedding data\n",
        "print(\"Note: for unknown words, the representation is an empty vector,\\n\"\n",
        "      \"and the index is the last one. The dictionnary has a limit:\")\n",
        "print(\"    {} --> {} --> {}\".format(\"A word\", \"Index in embedding\", \n",
        "      \"Representation\"))\n",
        "word = \"worsdfkljsdf\"  # a word obviously not in the vocabulary\n",
        "idx = word_to_index[word] # index for word obviously not in the vocabulary\n",
        "complete_vocabulary_size = idx \n",
        "embd = list(np.array(index_to_embedding[idx], dtype=int)) # \"int\" compact print\n",
        "print(\"    {} --> {} --> {}\".format(word, idx, embd))\n",
        "word = \"the\"\n",
        "idx = word_to_index[word]\n",
        "embd = list(index_to_embedding[idx])  # \"int\" for compact print only.\n",
        "print(\"    {} --> {} --> {}\".format(word, idx, embd))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding is of shape: (400001, 50)\n",
            "This means (number of words, number of dimensions per word)\n",
            "\n",
            "The first words are words that tend occur more often.\n",
            "Note: for unknown words, the representation is an empty vector,\n",
            "and the index is the last one. The dictionnary has a limit:\n",
            "    A word --> Index in embedding --> Representation\n",
            "    worsdfkljsdf --> 400000 --> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    the --> 0 --> [0.418, 0.24968, -0.41242, 0.1217, 0.34527, -0.044457, -0.49688, -0.17862, -0.00066023, -0.6566, 0.27843, -0.14767, -0.55677, 0.14658, -0.0095095, 0.011658, 0.10204, -0.12792, -0.8443, -0.12181, -0.016801, -0.33279, -0.1552, -0.23131, -0.19181, -1.8823, -0.76746, 0.099051, -0.42125, -0.19526, 4.0071, -0.18594, -0.52287, -0.31681, 0.00059213, 0.0074449, 0.17778, -0.15897, 0.012041, -0.054223, -0.29871, -0.15749, -0.34758, -0.045637, -0.44251, 0.18785, 0.0027849, -0.18411, -0.11514, -0.78581]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xivWaa9Mfclw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db159bb0-2273-424e-cee4-cc262c8fe61b"
      },
      "source": [
        "# Show how to use embeddings dictionaries with a test sentence\n",
        "# This is a famous typing exercise with all letters of the alphabet\n",
        "# https://en.wikipedia.org/wiki/The_quick_brown_fox_jumps_over_the_lazy_dog\n",
        "a_typing_test_sentence = 'The quick brown fox jumps over the lazy dog'\n",
        "print('\\nTest sentence: ', a_typing_test_sentence, '\\n')\n",
        "words_in_test_sentence = a_typing_test_sentence.split()\n",
        "\n",
        "print('Test sentence embeddings from complete vocabulary of', \n",
        "      complete_vocabulary_size, 'words:\\n')\n",
        "for word in words_in_test_sentence:\n",
        "    word_ = word.lower()\n",
        "    embedding = index_to_embedding[word_to_index[word_]]\n",
        "    print(word_ + \": \", embedding)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test sentence:  The quick brown fox jumps over the lazy dog \n",
            "\n",
            "Test sentence embeddings from complete vocabulary of 400000 words:\n",
            "\n",
            "the:  [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n",
            "quick:  [ 0.13967   -0.53798   -0.18047   -0.25142    0.16203   -0.13868\n",
            " -0.24637    0.75111    0.27264    0.61035   -0.82548    0.038647\n",
            " -0.32361    0.30373   -0.14598   -0.23551    0.39267   -1.1287\n",
            " -0.23636   -1.0629     0.046277   0.29143   -0.25819   -0.094902\n",
            "  0.79478   -1.2095    -0.01039   -0.092086   0.84322   -0.11061\n",
            "  3.0096     0.51652   -0.76986    0.51074    0.37508    0.12156\n",
            "  0.082794   0.43605   -0.1584    -0.61048    0.35006    0.52465\n",
            " -0.51747    0.0034705  0.73625    0.16252    0.85279    0.85268\n",
            "  0.57892    0.64483  ]\n",
            "brown:  [-0.88497   0.71685  -0.40379  -0.10698   0.81457   1.0258   -1.2698\n",
            " -0.49382  -0.27839  -0.92251  -0.49409   0.78942  -0.20066  -0.057371\n",
            "  0.060682  0.30746   0.13441  -0.49376  -0.54788  -0.81912  -0.45394\n",
            "  0.52098   1.0325   -0.8584   -0.65848  -1.2736    0.23616   1.0486\n",
            "  0.18442  -0.3901    2.1385   -0.45301  -0.16911  -0.46737   0.15938\n",
            " -0.095071 -0.26512  -0.056479  0.63849  -1.0494    0.037507  0.76434\n",
            " -0.6412   -0.59594   0.46589   0.31494  -0.34072  -0.59167  -0.31057\n",
            "  0.73274 ]\n",
            "fox:  [ 0.44206   0.059552  0.15861   0.92777   0.1876    0.24256  -1.593\n",
            " -0.79847  -0.34099  -0.24021  -0.32756   0.43639  -0.11057   0.50472\n",
            "  0.43853   0.19738  -0.1498   -0.046979 -0.83286   0.39878   0.062174\n",
            "  0.28803   0.79134   0.31798  -0.21933  -1.1015   -0.080309  0.39122\n",
            "  0.19503  -0.5936    1.7921    0.3826   -0.30509  -0.58686  -0.76935\n",
            " -0.61914  -0.61771  -0.68484  -0.67919  -0.74626  -0.036646  0.78251\n",
            " -1.0072   -0.59057  -0.7849   -0.39113  -0.49727  -0.4283   -0.15204\n",
            "  1.5064  ]\n",
            "jumps:  [-0.46105   -0.34219    0.71473   -0.29778    0.28839    0.6248\n",
            "  0.36807   -0.072746   0.60476    0.31463   -0.052247  -0.62302\n",
            " -0.56332    0.7855     0.18116   -0.31698    0.38298   -0.081953\n",
            " -1.3658    -0.78263    0.39804   -0.17001   -0.11926   -0.40146\n",
            "  1.1057    -0.51142   -0.36614    0.22177    0.34626   -0.30648\n",
            "  1.3869     0.77328    0.5946     1.2577     0.23472   -0.46087\n",
            " -0.009223   0.44534    0.012732  -0.24749   -0.7142     0.02422\n",
            "  0.083527   0.25088   -0.24259   -1.354      1.5481    -0.31728\n",
            "  0.55305   -0.0028062]\n",
            "over:  [ 0.12972    0.088073   0.24375    0.078102  -0.12783    0.27831\n",
            " -0.48693    0.19649   -0.39558   -0.28362   -0.47425   -0.59317\n",
            " -0.58804   -0.31702    0.49593    0.0087594  0.039613  -0.42495\n",
            " -0.97641   -0.46534    0.020675   0.086042   0.39317   -0.51255\n",
            " -0.17913   -1.8333     0.5622     0.41626    0.075127   0.02189\n",
            "  3.784      0.71067   -0.073943   0.15373   -0.3853    -0.070163\n",
            " -0.35374    0.074501  -0.084228  -0.45548   -0.081068   0.39157\n",
            "  0.173      0.2254    -0.12836    0.40951   -0.26079    0.090912\n",
            " -0.60515   -0.9827   ]\n",
            "the:  [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n",
            "lazy:  [-0.27611  -0.59712  -0.49227  -1.0372   -0.35878  -0.097425 -0.21014\n",
            " -0.092836 -0.054118  0.4542   -0.53296   0.37602   0.77087   0.79669\n",
            " -0.076608 -0.42515   0.42576   0.32791  -0.21996  -0.20261  -0.85139\n",
            "  0.80547   0.97621   0.9792    1.1118   -0.36062  -0.2588    0.8596\n",
            "  0.73631  -0.18601   1.2376   -0.038938  0.19246   0.52473  -0.04842\n",
            " -0.044149  0.064432  0.087822  0.42232  -0.55991  -0.44096   0.097736\n",
            " -0.17589   1.1799    0.13152  -1.0795    0.45685  -0.63312   1.2752\n",
            "  1.1672  ]\n",
            "dog:  [ 0.11008   -0.38781   -0.57615   -0.27714    0.70521    0.53994\n",
            " -1.0786    -0.40146    1.1504    -0.5678     0.0038977  0.52878\n",
            "  0.64561    0.47262    0.48549   -0.18407    0.1801     0.91397\n",
            " -1.1979    -0.5778    -0.37985    0.33606    0.772      0.75555\n",
            "  0.45506   -1.7671    -1.0503     0.42566    0.41893   -0.68327\n",
            "  1.5673     0.27685   -0.61708    0.64638   -0.076996   0.37118\n",
            "  0.1308    -0.45137    0.25398   -0.74392   -0.086199   0.24068\n",
            " -0.64819    0.83549    1.2502    -0.51379    0.04224   -0.88118\n",
            "  0.7158     0.38519  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iztcyBPNbIVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ------------------------------------------------------------- \n",
        "# Define vocabulary size for the language model    \n",
        "# To reduce the size of the vocabulary to the n most frequently used words\n",
        "\n",
        "def default_factory():\n",
        "    return EVOCABSIZE  # last/unknown-word row in limited_index_to_embedding\n",
        "# dictionary has the items() function, returns list of (key, value) tuples\n",
        "limited_word_to_index = defaultdict(default_factory, \\\n",
        "    {k: v for k, v in word_to_index.items() if v < EVOCABSIZE})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB0XpuOWgJGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the first EVOCABSIZE rows to the index_to_embedding\n",
        "limited_index_to_embedding = index_to_embedding[0:EVOCABSIZE,:]\n",
        "\n",
        "# Set the unknown-word row to be all zeros as previously\n",
        "limited_index_to_embedding = np.append(limited_index_to_embedding, \n",
        "    index_to_embedding[index_to_embedding.shape[0] - 1, :].\\\n",
        "        reshape(1,embedding_dim), \n",
        "    axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7D5PnQ0gLS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72711243-c74a-4f6c-8bcc-65ceed2a6e4d"
      },
      "source": [
        "# Verify the new vocabulary: should get same embeddings for test sentence\n",
        "# Note that a small EVOCABSIZE may yield some zero vectors for embeddings\n",
        "print('\\nTest sentence embeddings from vocabulary of', EVOCABSIZE, 'words:\\n')\n",
        "for word in words_in_test_sentence:\n",
        "    word_ = word.lower()\n",
        "    embedding = limited_index_to_embedding[limited_word_to_index[word_]]\n",
        "    print(word_ + \": \", embedding)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test sentence embeddings from vocabulary of 10000 words:\n",
            "\n",
            "the:  [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n",
            "quick:  [ 0.13967   -0.53798   -0.18047   -0.25142    0.16203   -0.13868\n",
            " -0.24637    0.75111    0.27264    0.61035   -0.82548    0.038647\n",
            " -0.32361    0.30373   -0.14598   -0.23551    0.39267   -1.1287\n",
            " -0.23636   -1.0629     0.046277   0.29143   -0.25819   -0.094902\n",
            "  0.79478   -1.2095    -0.01039   -0.092086   0.84322   -0.11061\n",
            "  3.0096     0.51652   -0.76986    0.51074    0.37508    0.12156\n",
            "  0.082794   0.43605   -0.1584    -0.61048    0.35006    0.52465\n",
            " -0.51747    0.0034705  0.73625    0.16252    0.85279    0.85268\n",
            "  0.57892    0.64483  ]\n",
            "brown:  [-0.88497   0.71685  -0.40379  -0.10698   0.81457   1.0258   -1.2698\n",
            " -0.49382  -0.27839  -0.92251  -0.49409   0.78942  -0.20066  -0.057371\n",
            "  0.060682  0.30746   0.13441  -0.49376  -0.54788  -0.81912  -0.45394\n",
            "  0.52098   1.0325   -0.8584   -0.65848  -1.2736    0.23616   1.0486\n",
            "  0.18442  -0.3901    2.1385   -0.45301  -0.16911  -0.46737   0.15938\n",
            " -0.095071 -0.26512  -0.056479  0.63849  -1.0494    0.037507  0.76434\n",
            " -0.6412   -0.59594   0.46589   0.31494  -0.34072  -0.59167  -0.31057\n",
            "  0.73274 ]\n",
            "fox:  [ 0.44206   0.059552  0.15861   0.92777   0.1876    0.24256  -1.593\n",
            " -0.79847  -0.34099  -0.24021  -0.32756   0.43639  -0.11057   0.50472\n",
            "  0.43853   0.19738  -0.1498   -0.046979 -0.83286   0.39878   0.062174\n",
            "  0.28803   0.79134   0.31798  -0.21933  -1.1015   -0.080309  0.39122\n",
            "  0.19503  -0.5936    1.7921    0.3826   -0.30509  -0.58686  -0.76935\n",
            " -0.61914  -0.61771  -0.68484  -0.67919  -0.74626  -0.036646  0.78251\n",
            " -1.0072   -0.59057  -0.7849   -0.39113  -0.49727  -0.4283   -0.15204\n",
            "  1.5064  ]\n",
            "jumps:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "over:  [ 0.12972    0.088073   0.24375    0.078102  -0.12783    0.27831\n",
            " -0.48693    0.19649   -0.39558   -0.28362   -0.47425   -0.59317\n",
            " -0.58804   -0.31702    0.49593    0.0087594  0.039613  -0.42495\n",
            " -0.97641   -0.46534    0.020675   0.086042   0.39317   -0.51255\n",
            " -0.17913   -1.8333     0.5622     0.41626    0.075127   0.02189\n",
            "  3.784      0.71067   -0.073943   0.15373   -0.3853    -0.070163\n",
            " -0.35374    0.074501  -0.084228  -0.45548   -0.081068   0.39157\n",
            "  0.173      0.2254    -0.12836    0.40951   -0.26079    0.090912\n",
            " -0.60515   -0.9827   ]\n",
            "the:  [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n",
            "lazy:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "dog:  [ 0.11008   -0.38781   -0.57615   -0.27714    0.70521    0.53994\n",
            " -1.0786    -0.40146    1.1504    -0.5678     0.0038977  0.52878\n",
            "  0.64561    0.47262    0.48549   -0.18407    0.1801     0.91397\n",
            " -1.1979    -0.5778    -0.37985    0.33606    0.772      0.75555\n",
            "  0.45506   -1.7671    -1.0503     0.42566    0.41893   -0.68327\n",
            "  1.5673     0.27685   -0.61708    0.64638   -0.076996   0.37118\n",
            "  0.1308    -0.45137    0.25398   -0.74392   -0.086199   0.24068\n",
            " -0.64819    0.83549    1.2502    -0.51379    0.04224   -0.88118\n",
            "  0.7158     0.38519  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7ocFaCpbKLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ------------------------------------------------------------\n",
        "# code for working with movie reviews data \n",
        "# Source: Miller, T. W. (2016). Web and Network Data Science.\n",
        "#    Upper Saddle River, N.J.: Pearson Education.\n",
        "#    ISBN-13: 978-0-13-388644-3\n",
        "# This original study used a simple bag-of-words approach\n",
        "# to sentiment analysis, along with pre-defined lists of\n",
        "# negative and positive words.        \n",
        "# Code available at:  https://github.com/mtpa/wnds       \n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# Utility function to get file names within a directory\n",
        "def listdir_no_hidden(path):\n",
        "    start_list = os.listdir(path)\n",
        "    end_list = []\n",
        "    for file in start_list:\n",
        "        if (not file.startswith('.')):\n",
        "            end_list.append(file)\n",
        "    return(end_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FGZvXLgcp17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define list of codes to be dropped from document\n",
        "# carriage-returns, line-feeds, tabs\n",
        "codelist = ['\\r', '\\n', '\\t']   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECTuyN6-ehz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will not remove stopwords in this exercise because they are\n",
        "# important to keeping sentences intact\n",
        "if REMOVE_STOPWORDS:\n",
        "    print(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# previous analysis of a list of top terms showed a number of words, along \n",
        "# with contractions and other word strings to drop from further analysis, add\n",
        "# these to the usual English stopwords to be dropped from a document collection\n",
        "    more_stop_words = ['cant','didnt','doesnt','dont','goes','isnt','hes',\\\n",
        "        'shes','thats','theres','theyre','wont','youll','youre','youve', 'br'\\\n",
        "        've', 're', 'vs'] \n",
        "\n",
        "    some_proper_nouns_to_remove = ['dick','ginger','hollywood','jack',\\\n",
        "        'jill','john','karloff','kudrow','orson','peter','tcm','tom',\\\n",
        "        'toni','welles','william','wolheim','nikita']\n",
        "\n",
        "    # start with the initial list and add to it for movie text work \n",
        "    stoplist = nltk.corpus.stopwords.words('english') + more_stop_words +\\\n",
        "        some_proper_nouns_to_remove"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPrXjschgU4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text parsing function for creating text documents \n",
        "# there is more we could do for data preparation \n",
        "# stemming... looking for contractions... possessives... \n",
        "# but we will work with what we have in this parsing function\n",
        "# if we want to do stemming at a later time, we can use\n",
        "#     porter = nltk.PorterStemmer()  \n",
        "# in a construction like this\n",
        "#     words_stemmed =  [porter.stem(word) for word in initial_words]  \n",
        "def text_parse(string):\n",
        "    # replace non-alphanumeric with space \n",
        "    temp_string = re.sub('[^a-zA-Z]', '  ', string)    \n",
        "    # replace codes with space\n",
        "    for i in range(len(codelist)):\n",
        "        stopstring = ' ' + codelist[i] + '  '\n",
        "        temp_string = re.sub(stopstring, '  ', temp_string)      \n",
        "    # replace single-character words with space\n",
        "    temp_string = re.sub('\\s.\\s', ' ', temp_string)   \n",
        "    # convert uppercase to lowercase\n",
        "    temp_string = temp_string.lower()    \n",
        "    if REMOVE_STOPWORDS:\n",
        "        # replace selected character strings/stop-words with space\n",
        "        for i in range(len(stoplist)):\n",
        "            stopstring = ' ' + str(stoplist[i]) + ' '\n",
        "            temp_string = re.sub(stopstring, ' ', temp_string)        \n",
        "    # replace multiple blank characters with one blank character\n",
        "    temp_string = re.sub('\\s+', ' ', temp_string)    \n",
        "    return(temp_string)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV8LQ0tljC-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "182395f1-51d3-4c3f-fc1c-4e7fae417536"
      },
      "source": [
        "print(os.getcwd())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBePq8HEgWkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ce1e3867-d020-4109-a292-25884d497c6f"
      },
      "source": [
        "# -----------------------------------------------\n",
        "# Download and install both negtive and positive movies reviews from the Technology Resources Section \n",
        "# within the Jump Start Program for Assignment 8 Module. This entails saving the 'movie-reviews-negative'\n",
        "# and 'movie-reviews-positive' directories from the run-jump-start-rnn-sentiment-v002.zip \n",
        "# or  run-jump-start-rnn-sentiment-big-v002.zip file to your working directory\n",
        "# -----------------------------------------------\n",
        "\n",
        "# -----------------------------------------------\n",
        "# gather data for 500 negative movie reviews\n",
        "# -----------------------------------------------\n",
        "\n",
        "# Set path to the negative word dictionary, \"moive-reviews-negative\"\n",
        "dir_name = 'movie-reviews-negative'\n",
        "filenames = listdir_no_hidden(path=dir_name)\n",
        "num_files = len(filenames)\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    file_exists = os.path.isfile(os.path.join(dir_name, filenames[i]))\n",
        "    assert file_exists\n",
        "print('\\nDirectory:',dir_name)    \n",
        "print('%d files found' % len(filenames))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Directory: movie-reviews-negative\n",
            "500 files found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c38QUr9gZBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b3c0e99-23a8-4c6a-c694-dafc2d8f6d34"
      },
      "source": [
        "# Read data for negative movie reviews\n",
        "# Data will be stored in a list of lists where the each list represents \n",
        "# a document and document is a list of words.\n",
        "# We then break the text into words.\n",
        "\n",
        "def read_data(filename):\n",
        "\n",
        "  with open(filename, encoding='utf-8') as f:\n",
        "    data = tf.compat.as_str(f.read())\n",
        "    data = data.lower()\n",
        "    data = text_parse(data)\n",
        "    data = TreebankWordTokenizer().tokenize(data)  # The Penn Treebank\n",
        "\n",
        "  return data\n",
        "\n",
        "negative_documents = []\n",
        "\n",
        "print('\\nProcessing document files under', dir_name)\n",
        "for i in range(num_files):\n",
        "    ## print(' ', filenames[i])\n",
        "\n",
        "    words = read_data(os.path.join(dir_name, filenames[i]))\n",
        "\n",
        "    negative_documents.append(words)\n",
        "    # print('Data size (Characters) (Document %d) %d' %(i,len(words)))\n",
        "    # print('Sample string (Document %d) %s'%(i,words[:50]))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing document files under movie-reviews-negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E9Qp2DBmRMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8edef014-5828-4d0f-9dc7-e0063205e986"
      },
      "source": [
        "# -----------------------------------------------\n",
        "# gather data for 500 positive movie reviews\n",
        "# -----------------------------------------------\n",
        "\n",
        "# Set path to the positive word dictionary, \"moive-reviews-positive\"\n",
        "dir_name = 'movie-reviews-positive'  \n",
        "filenames = listdir_no_hidden(path=dir_name)\n",
        "num_files = len(filenames)\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    file_exists = os.path.isfile(os.path.join(dir_name, filenames[i]))\n",
        "    assert file_exists\n",
        "print('\\nDirectory:',dir_name)    \n",
        "print('%d files found' % len(filenames))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Directory: movie-reviews-positive\n",
            "500 files found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BbO9e3EmTsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f60f9352-80db-4d38-abac-76d7852665a5"
      },
      "source": [
        "# Read data for positive movie reviews\n",
        "# Data will be stored in a list of lists where the each list \n",
        "# represents a document and document is a list of words.\n",
        "# We then break the text into words.\n",
        "\n",
        "def read_data(filename):\n",
        "\n",
        "  with open(filename, encoding='utf-8') as f:\n",
        "    data = tf.compat.as_str(f.read())\n",
        "    data = data.lower()\n",
        "    data = text_parse(data)\n",
        "    data = TreebankWordTokenizer().tokenize(data)  # The Penn Treebank\n",
        "\n",
        "  return data\n",
        "\n",
        "positive_documents = []\n",
        "\n",
        "print('\\nProcessing document files under', dir_name)\n",
        "for i in range(num_files):\n",
        "    ## print(' ', filenames[i])\n",
        "\n",
        "    words = read_data(os.path.join(dir_name, filenames[i]))\n",
        "\n",
        "    positive_documents.append(words)\n",
        "    # print('Data size (Characters) (Document %d) %d' %(i,len(words)))\n",
        "    # print('Sample string (Document %d) %s'%(i,words[:50]))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing document files under movie-reviews-positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn7f8uggnCga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "83e6b781-d0a3-4c78-b873-82628060dd70"
      },
      "source": [
        "# -----------------------------------------------------\n",
        "# convert positive/negative documents into numpy array\n",
        "# note that reviews vary from 22 to 1052 words   \n",
        "# so we use the first 20 and last 20 words of each review \n",
        "# as our word sequences for analysis\n",
        "# -----------------------------------------------------\n",
        "\n",
        "max_review_length = 0  # initialize\n",
        "for doc in negative_documents:\n",
        "    max_review_length = max(max_review_length, len(doc))    \n",
        "for doc in positive_documents:\n",
        "    max_review_length = max(max_review_length, len(doc)) \n",
        "print('max_review_length:', max_review_length) \n",
        "\n",
        "min_review_length = max_review_length  # initialize\n",
        "for doc in negative_documents:\n",
        "    min_review_length = min(min_review_length, len(doc))    \n",
        "for doc in positive_documents:\n",
        "    min_review_length = min(min_review_length, len(doc)) \n",
        "print('min_review_length:', min_review_length) "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_review_length: 1052\n",
            "min_review_length: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qz77iPw_Ko-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct list of 1000 lists with 40 words in each list\n",
        "from itertools import chain\n",
        "documents = []\n",
        "for doc in negative_documents:\n",
        "    doc_begin = doc[0:20]\n",
        "    doc_end = doc[len(doc) - 20: len(doc)]\n",
        "    documents.append(list(chain(*[doc_begin, doc_end])))    \n",
        "for doc in positive_documents:\n",
        "    doc_begin = doc[0:20]\n",
        "    doc_end = doc[len(doc) - 20: len(doc)]\n",
        "    documents.append(list(chain(*[doc_begin, doc_end])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I6iZZDhyyeN",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Get Word Embeddings from Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o0Q0QuszBOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 10000   #specify desired size of pre-defined embedding vocabulary \n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(documents)\n",
        "\n",
        "# integer encode the documents\n",
        "sequences = tokenizer.texts_to_sequences(documents)\n",
        "embeddings = pad_sequences(sequences, maxlen=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo66vx-zGWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "281abbd9-593a-4d48-b802-37794bc9f1d1"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('embeddings/gloVe.6B/glove.6B.50d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3rfJVlYzMOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocabulary_size, 50))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdSPpwG9zPDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------    \n",
        "# Make embeddings a numpy array for use in an RNN \n",
        "# Create training and test sets with Scikit Learn\n",
        "# -----------------------------------------------------\n",
        "RANDOM_SEED = 9999\n",
        "\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Define the labels to be used 500 negative (0) and 500 positive (1)\n",
        "thumbs_down_up = np.concatenate((np.zeros((500), dtype = np.int32), \n",
        "                      np.ones((500), dtype = np.int32)), axis = 0)\n",
        "\n",
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(embeddings_array, thumbs_down_up, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-e7r9hQzRHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e15a3b1-a440-42b7-8e63-965ab4cbf20a"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSC11TxWzSyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aefec17a-bf84-44eb-9af4-46d5183f8093"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1kEYQW3nxOo",
        "colab_type": "text"
      },
      "source": [
        "# 2. Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvwnD3rtpLqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To make output stable across runs\n",
        "def reset_graph(seed= RANDOM_SEED):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rBN7AC3nhm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training base model by using RNN backpropagation through time (BPTT).\n",
        "reset_graph() # Refresh graph to make output stable across runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpg1kqZC27z",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 RNN with LSTM\n",
        "Vocabulary size 10,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhIWH2IQvBPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "a0085e03-1053-405f-b6d4-a4977bdf4b53"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(EVOCABSIZE, 50, input_length=50, trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 50)            500000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 46, 64)            16064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 11, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50)                23000     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 539,115\n",
            "Trainable params: 39,115\n",
            "Non-trainable params: 500,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_P0wgnvUl8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2561e8f6-cd35-472d-f799-4485bf537d80"
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.6939 - acc: 0.4850 - val_loss: 0.6932 - val_acc: 0.4650\n",
            "Epoch 2/30\n",
            "800/800 [==============================] - 1s 774us/step - loss: 0.6923 - acc: 0.5212 - val_loss: 0.6943 - val_acc: 0.4700\n",
            "Epoch 3/30\n",
            "800/800 [==============================] - 1s 794us/step - loss: 0.6905 - acc: 0.5437 - val_loss: 0.6929 - val_acc: 0.4700\n",
            "Epoch 4/30\n",
            "800/800 [==============================] - 1s 800us/step - loss: 0.6880 - acc: 0.5413 - val_loss: 0.6908 - val_acc: 0.5500\n",
            "Epoch 5/30\n",
            "800/800 [==============================] - 1s 843us/step - loss: 0.6819 - acc: 0.5825 - val_loss: 0.6890 - val_acc: 0.5450\n",
            "Epoch 6/30\n",
            "800/800 [==============================] - 1s 812us/step - loss: 0.6727 - acc: 0.6025 - val_loss: 0.6995 - val_acc: 0.5000\n",
            "Epoch 7/30\n",
            "800/800 [==============================] - 1s 765us/step - loss: 0.6571 - acc: 0.6275 - val_loss: 0.6869 - val_acc: 0.5700\n",
            "Epoch 8/30\n",
            "800/800 [==============================] - 1s 789us/step - loss: 0.6264 - acc: 0.6375 - val_loss: 0.6767 - val_acc: 0.5450\n",
            "Epoch 9/30\n",
            "800/800 [==============================] - 1s 748us/step - loss: 0.6165 - acc: 0.6487 - val_loss: 0.6808 - val_acc: 0.5350\n",
            "Epoch 10/30\n",
            "800/800 [==============================] - 1s 678us/step - loss: 0.6051 - acc: 0.6737 - val_loss: 0.6781 - val_acc: 0.5650\n",
            "Epoch 11/30\n",
            "800/800 [==============================] - 1s 760us/step - loss: 0.5960 - acc: 0.6837 - val_loss: 0.6952 - val_acc: 0.5750\n",
            "Epoch 12/30\n",
            "800/800 [==============================] - 1s 826us/step - loss: 0.5625 - acc: 0.7250 - val_loss: 0.6910 - val_acc: 0.5850\n",
            "Epoch 13/30\n",
            "800/800 [==============================] - 1s 772us/step - loss: 0.5425 - acc: 0.7275 - val_loss: 0.6832 - val_acc: 0.5900\n",
            "Epoch 14/30\n",
            "800/800 [==============================] - 1s 790us/step - loss: 0.5243 - acc: 0.7450 - val_loss: 0.7232 - val_acc: 0.5500\n",
            "Epoch 15/30\n",
            "800/800 [==============================] - 1s 767us/step - loss: 0.4738 - acc: 0.7900 - val_loss: 0.6995 - val_acc: 0.5900\n",
            "Epoch 16/30\n",
            "800/800 [==============================] - 1s 776us/step - loss: 0.4564 - acc: 0.7875 - val_loss: 0.7180 - val_acc: 0.6150\n",
            "Epoch 17/30\n",
            "800/800 [==============================] - 1s 771us/step - loss: 0.4128 - acc: 0.8225 - val_loss: 0.6898 - val_acc: 0.6050\n",
            "Epoch 18/30\n",
            "800/800 [==============================] - 1s 768us/step - loss: 0.3584 - acc: 0.8500 - val_loss: 0.7560 - val_acc: 0.5700\n",
            "Epoch 19/30\n",
            "800/800 [==============================] - 1s 733us/step - loss: 0.3325 - acc: 0.8588 - val_loss: 0.7147 - val_acc: 0.6300\n",
            "Epoch 20/30\n",
            "800/800 [==============================] - 1s 786us/step - loss: 0.3357 - acc: 0.8612 - val_loss: 0.7163 - val_acc: 0.6000\n",
            "Epoch 21/30\n",
            "800/800 [==============================] - 1s 792us/step - loss: 0.3190 - acc: 0.8825 - val_loss: 0.7094 - val_acc: 0.5950\n",
            "Epoch 22/30\n",
            "800/800 [==============================] - 1s 811us/step - loss: 0.2505 - acc: 0.9000 - val_loss: 0.7719 - val_acc: 0.6200\n",
            "Epoch 23/30\n",
            "800/800 [==============================] - 1s 794us/step - loss: 0.2350 - acc: 0.9100 - val_loss: 0.7874 - val_acc: 0.6050\n",
            "Epoch 24/30\n",
            "800/800 [==============================] - 1s 793us/step - loss: 0.2694 - acc: 0.8875 - val_loss: 0.7737 - val_acc: 0.5900\n",
            "Epoch 25/30\n",
            "800/800 [==============================] - 1s 778us/step - loss: 0.2131 - acc: 0.9187 - val_loss: 0.9102 - val_acc: 0.6050\n",
            "Epoch 26/30\n",
            "800/800 [==============================] - 1s 813us/step - loss: 0.1798 - acc: 0.9325 - val_loss: 0.7966 - val_acc: 0.6000\n",
            "Epoch 27/30\n",
            "800/800 [==============================] - 1s 796us/step - loss: 0.1740 - acc: 0.9375 - val_loss: 0.8227 - val_acc: 0.6050\n",
            "Epoch 28/30\n",
            "800/800 [==============================] - 1s 763us/step - loss: 0.1817 - acc: 0.9187 - val_loss: 0.8566 - val_acc: 0.6050\n",
            "Epoch 29/30\n",
            "800/800 [==============================] - 1s 818us/step - loss: 0.1488 - acc: 0.9462 - val_loss: 0.9208 - val_acc: 0.6200\n",
            "Epoch 30/30\n",
            "800/800 [==============================] - 1s 810us/step - loss: 0.1508 - acc: 0.9450 - val_loss: 0.9402 - val_acc: 0.6100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X4p7Q-TvbGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d8557905-2757-493f-90ca-9ab6e5018973"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "score, acc = model.evaluate(X_train, y_train, batch_size=batch_size)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)\n",
        "\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 0s 127us/step\n",
            "Train score: 0.02852854400873184\n",
            "Train accuracy: 1.0\n",
            "200/200 [==============================] - 0s 141us/step\n",
            "Test score: 0.9401653575897216\n",
            "Test accuracy: 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQwsFqHRzqj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "64252f59-c3ad-48c7-a0b5-e06236177a73"
      },
      "source": [
        "# Plot the accuracy curves for training and validation \n",
        "pyplot.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "pyplot.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "legend = pyplot.legend(loc='best', shadow=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOietoucAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4laAAz3z2GR",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 RNN with LSTM\n",
        "Embedded vocabulary size increased to 30,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXUtH-tVzvbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 30000   #specify desired size of pre-defined embedding vocabulary \n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(documents)\n",
        "\n",
        "# integer encode the documents\n",
        "sequences = tokenizer.texts_to_sequences(documents)\n",
        "embeddings = pad_sequences(sequences, maxlen=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAtU0KFd0D5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1c19ccf-3e25-4df1-aa5c-da875b94ed4a"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('embeddings/gloVe.6B/glove.6B.50d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocabulary_size, 50))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M1uaLQj0FcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------    \n",
        "# Make embeddings a numpy array for use in an RNN \n",
        "# Create training and test sets with Scikit Learn\n",
        "# -----------------------------------------------------\n",
        "RANDOM_SEED = 9999\n",
        "\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Define the labels to be used 500 negative (0) and 500 positive (1)\n",
        "thumbs_down_up = np.concatenate((np.zeros((500), dtype = np.int32), \n",
        "                      np.ones((500), dtype = np.int32)), axis = 0)\n",
        "\n",
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(embeddings_array, thumbs_down_up, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCoHykZB0IBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "364385ab-54eb-4489-c303-e8f7f2dcea31"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 50, input_length=50, trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 50, 50)            1500000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 46, 64)            16064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 11, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                23000     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 1,539,115\n",
            "Trainable params: 39,115\n",
            "Non-trainable params: 1,500,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8lALTsQ0Jvz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "442310ed-bbfa-456e-9114-eeb7459d432c"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/30\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.6934 - acc: 0.5038 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 2/30\n",
            "800/800 [==============================] - 1s 823us/step - loss: 0.6923 - acc: 0.5212 - val_loss: 0.6927 - val_acc: 0.4950\n",
            "Epoch 3/30\n",
            "800/800 [==============================] - 1s 850us/step - loss: 0.6900 - acc: 0.5413 - val_loss: 0.6902 - val_acc: 0.5750\n",
            "Epoch 4/30\n",
            "800/800 [==============================] - 1s 840us/step - loss: 0.6846 - acc: 0.6100 - val_loss: 0.6901 - val_acc: 0.5050\n",
            "Epoch 5/30\n",
            "800/800 [==============================] - 1s 846us/step - loss: 0.6769 - acc: 0.5862 - val_loss: 0.6885 - val_acc: 0.5200\n",
            "Epoch 6/30\n",
            "800/800 [==============================] - 1s 819us/step - loss: 0.6639 - acc: 0.6112 - val_loss: 0.6731 - val_acc: 0.5950\n",
            "Epoch 7/30\n",
            "800/800 [==============================] - 1s 851us/step - loss: 0.6440 - acc: 0.6400 - val_loss: 0.6657 - val_acc: 0.5800\n",
            "Epoch 8/30\n",
            "800/800 [==============================] - 1s 872us/step - loss: 0.6155 - acc: 0.6812 - val_loss: 0.6636 - val_acc: 0.5550\n",
            "Epoch 9/30\n",
            "800/800 [==============================] - 1s 879us/step - loss: 0.6135 - acc: 0.6763 - val_loss: 0.6614 - val_acc: 0.5900\n",
            "Epoch 10/30\n",
            "800/800 [==============================] - 1s 854us/step - loss: 0.5903 - acc: 0.6925 - val_loss: 0.6612 - val_acc: 0.5950\n",
            "Epoch 11/30\n",
            "800/800 [==============================] - 1s 782us/step - loss: 0.5617 - acc: 0.7350 - val_loss: 0.6755 - val_acc: 0.5400\n",
            "Epoch 12/30\n",
            "800/800 [==============================] - 1s 786us/step - loss: 0.5334 - acc: 0.7475 - val_loss: 0.6730 - val_acc: 0.6150\n",
            "Epoch 13/30\n",
            "800/800 [==============================] - 1s 792us/step - loss: 0.5234 - acc: 0.7538 - val_loss: 0.7388 - val_acc: 0.5350\n",
            "Epoch 14/30\n",
            "800/800 [==============================] - 1s 797us/step - loss: 0.5003 - acc: 0.7638 - val_loss: 0.6777 - val_acc: 0.5950\n",
            "Epoch 15/30\n",
            "800/800 [==============================] - 1s 820us/step - loss: 0.4584 - acc: 0.8013 - val_loss: 0.7179 - val_acc: 0.5900\n",
            "Epoch 16/30\n",
            "800/800 [==============================] - 1s 789us/step - loss: 0.4566 - acc: 0.7787 - val_loss: 0.7938 - val_acc: 0.5600\n",
            "Epoch 17/30\n",
            "800/800 [==============================] - 1s 769us/step - loss: 0.4100 - acc: 0.8137 - val_loss: 0.7240 - val_acc: 0.5750\n",
            "Epoch 18/30\n",
            "800/800 [==============================] - 1s 817us/step - loss: 0.3619 - acc: 0.8387 - val_loss: 0.6959 - val_acc: 0.5750\n",
            "Epoch 19/30\n",
            "800/800 [==============================] - 1s 716us/step - loss: 0.3301 - acc: 0.8513 - val_loss: 0.6936 - val_acc: 0.6050\n",
            "Epoch 20/30\n",
            "800/800 [==============================] - 1s 718us/step - loss: 0.3126 - acc: 0.8750 - val_loss: 0.7322 - val_acc: 0.5950\n",
            "Epoch 21/30\n",
            "800/800 [==============================] - 1s 727us/step - loss: 0.2835 - acc: 0.8788 - val_loss: 0.6882 - val_acc: 0.5850\n",
            "Epoch 22/30\n",
            "800/800 [==============================] - 1s 716us/step - loss: 0.2796 - acc: 0.8837 - val_loss: 0.7694 - val_acc: 0.5950\n",
            "Epoch 23/30\n",
            "800/800 [==============================] - 1s 736us/step - loss: 0.2328 - acc: 0.9050 - val_loss: 1.2228 - val_acc: 0.5300\n",
            "Epoch 24/30\n",
            "800/800 [==============================] - 1s 822us/step - loss: 0.2383 - acc: 0.9125 - val_loss: 0.7413 - val_acc: 0.5900\n",
            "Epoch 25/30\n",
            "800/800 [==============================] - 1s 878us/step - loss: 0.2459 - acc: 0.9037 - val_loss: 0.7529 - val_acc: 0.5950\n",
            "Epoch 26/30\n",
            "800/800 [==============================] - 1s 761us/step - loss: 0.2311 - acc: 0.9037 - val_loss: 0.7165 - val_acc: 0.6300\n",
            "Epoch 27/30\n",
            "800/800 [==============================] - 1s 758us/step - loss: 0.1907 - acc: 0.9337 - val_loss: 0.8697 - val_acc: 0.5950\n",
            "Epoch 28/30\n",
            "800/800 [==============================] - 1s 752us/step - loss: 0.1708 - acc: 0.9312 - val_loss: 0.8723 - val_acc: 0.5900\n",
            "Epoch 29/30\n",
            "800/800 [==============================] - 1s 762us/step - loss: 0.1495 - acc: 0.9525 - val_loss: 0.8688 - val_acc: 0.6150\n",
            "Epoch 30/30\n",
            "800/800 [==============================] - 1s 677us/step - loss: 0.1375 - acc: 0.9600 - val_loss: 0.9007 - val_acc: 0.5950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnWB_-3V0NG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "230fc85e-88c2-4fdb-b70a-ac3287e65ea5"
      },
      "source": [
        "score, acc = model.evaluate(X_train, y_train, batch_size=batch_size)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)\n",
        "\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "# Plot the accuracy curves for training and validation \n",
        "pyplot.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "pyplot.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "legend = pyplot.legend(loc='best', shadow=True)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 0s 121us/step\n",
            "Train score: 0.030253894999623297\n",
            "Train accuracy: 1.0\n",
            "200/200 [==============================] - 0s 131us/step\n",
            "Test score: 0.9007147288322449\n",
            "Test accuracy: 0.595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZyNdfvA8c/XIDtjSSKRZJ9hDCJZ\nsyRLZI1sSQktnuohnqLSU0+Iyq9Ntoohsm8RkST7kqVQym6EsQ1jZr6/P66ZMcYsZ2bOzH3Omev9\nes1r5pxzL9d9zpnr/t7f7TbWWpRSSvmGbE4HoJRSyn00qSullA/RpK6UUj5Ek7pSSvkQTepKKeVD\nsju146JFi9oyZco4tXullPJKW7duPWOtLZbU644l9TJlyrBlyxandq+UUl7JGPNXcq9r9YtSSvkQ\nTepKKeVDNKkrpZQPcaxOPTEREREcOnSIK1euOB2K8iB58uShXLly5MyZ0+lQlPJ4HpXUDx06RKFC\nhahQoQLZsulFhILo6GhOnTrFwYMHqVy5stPhKOXxPCpzXrlyheLFi2tCV3GyZctG8eLFuXLlCn//\n/bfT4Sjl8Twue2pCVwlly5YNYwyLFi3i2rVrToejlEfTDKq8RlRUFJcvX3Y6DKXSJDoatmyBUaNg\n586M249H1ak77Z9//qFp06YAnDx5Ej8/P4oVk4FbmzZtcqmhrk+fPgwdOpQKFSokuczEiRMpVKgQ\n3bt3d0/gWYjO/6+8SVgYfPcdLF0Ky5bBqVNgDNx+OwQGZsw+NanHU6RIEXbs2AHAyJEjyZcvHy+9\n9NJNy1hrsdYmWU00ZcqUFPczcODA9AebySIjI8meXb8uSiXHWti3D5YskUS+fj1ERoK/P7RoAY88\nIr+LJTnIP/20+sUFsT0vunfvTpUqVThx4gT9+/cnODiYKlWq8MYbb8QtW79+fXbs2EFkZCSFChVi\n6NChBAYGUrduXU6fPg3AiBEjGD9+fNzyQ4cOpXbt2lSoUIENGzYAcPnyZR577DEqV65Mx44dCQ4O\njjvhxPf6669Tq1YtqlatyjPPPBNXkv39999p0qQJgYGBBAUFcfjwYQDefvttqlWrRmBgIMOHD78p\nZpArlHvvvReASZMm8eijj9K4cWNatGjBhQsXaNKkCUFBQQQEBLB48eK4OKZMmUJAQACBgYH06dOH\nsLAw7rnnHiIjIwE4d+7cTY+V8iV798LAgXDPPVClCrzyCpw9Cy+/DD/+CKdPw8yZ0KNHxiZ08OCS\n+gsvQCI5LF2qV4eYXJpq+/fvZ/r06QQHBwPwzjvvULhwYSIjI2ncuDEdO3a8pctdWFgYDRs25J13\n3mHIkCFMnjyZoUOH3rJtay2bNm1i4cKFvPHGGyxfvpwPP/yQO+64g7lz57Jz506CgoISjev5559n\n1KhRWGt5/PHHWb58OQ8//DDdunVj5MiRtGnThqtXrxIdHc2iRYtYtmwZmzZtInfu3Jw9ezbF496+\nfTs7duzA39+f69evM3/+fAoUKMDp06d54IEHaN26NTt37uTdd99lw4YNFC5cmLNnz1KwYEEeeOAB\nli9fTuvWrZk5cyadOnXS0r7yOfPnS7K2Fh56CIYNg1atoFQpZ+LRkrqLypUrF5fQAWbOnElQUBBB\nQUHs27ePvXv33rJO7ty5efjhhwGoWbNmXGk5oQ4dOtyyzPr16+natSsAgYGBVKlSJdF1v//+e2rX\nrk1gYCBr165lz549nDt3jjNnztCmTRsAcuXKRZ48eVi1ahV9+/Yld+7cABQuXDjF427evDn+/v6A\nnHyGDh1KQEAAzZs358iRI5w5c4bVq1fTpUuXuO3F/u7Xr19cddSUKVPo06dPivtTyltYC6NHQ/v2\nUjo/cAAWLID+/Z1L6ODBJfW0lqgzSt68eeP+PnDgABMmTGDTpk0UKlSIHj16cPXq1VvWid+w6ufn\nl2TVw2233ZbiMom5cuUKgwYNYtu2bZQsWZIRI0YkGkdKsmfPTnR0NMAt68c/7unTpxMWFsa2bdvI\nnj07pUqVSnZ/DRs2ZNCgQaxZs4YcOXJQsWLFVMemlCcKD4e+fSEkBLp3h88/h5iykuO0pJ4GFy5c\nIH/+/BQoUIATJ06wYsUKt+/jgQceYPbs2QDs3r070SuB8PBwsmXLRtGiRbl48SJz584FwN/fn2LF\nirFo0SJAEvWVK1do1qwZkydPJjw8HCCu+qVMmTJs3boVgDlz5iQZU1hYGLfffjvZs2dn5cqVHDt2\nDIAmTZowa9asuO3Fr9bp0aMH3bt311K68hnHjsGDD8KsWfDf/8KXX3pOQgdN6mkSFBRE5cqVqVix\nIj179uSBBx5w+z4GDx7MsWPHqFy5MqNGjaJy5coULFjwpmWKFClCr169qFy5Mg8//DB16tSJe+3r\nr79m7NixBAQEUL9+fUJDQ2ndujUtW7YkODiY6tWr8/777wPw8ssvM2HCBIKCgjh37lySMT3xxBNs\n2LCBatWqERISQvny5QGpHnrllVdo0KAB1atX5+WXX45bp3v37oSFhdGlSxd3vj1KOeKXXyA4GH77\nTapahg6VLoqexDjV7zc4ONgmvEnG1q1bqVmzpiPxeJrIyEgiIyPJlSsXBw4coHnz5hw4cMDrGhpD\nQkJYsWKFS109k7N161Z++uknunfvTpEiRdwUnVKu+/prePJJuPNOWLgQqlZ1Jg5jzFZrbXBSr3tX\nhshCLl26RNOmTYmMjMRay6effup1CX3AgAGsWrWK5cuXOx2KUmkWHQ3Dh8M770DDhjBnDhQt6nRU\nSfOuLJGFFCpUKK6e21t9/PHHToeg1C0mT4YvvpD+4iVK3Ppzxx1QvDhkzw4XLkh3xUWL4Omn4YMP\nwNNngNakrpTKMubPh379oEIFSdjr18M//9y6nDGS9K2VQUQffQTPPut59eeJ0aSulMoStmyR7oe1\nasEPP9zosRIRASdPys+JEzf/nDsHAwZAkyaOhp4qmtSVUj7v77+hTRspfS9ceHMXxJw5oXRp+fEF\nmtSVUj7twgWZSCs8HL7/XurLfZn2U4+ncePGtwwkGj9+PAMGDEh2vXz58gFw/PhxOnbsmOgyjRo1\nImEXzoTGjx9/0/1ZW7Vqxfnz510JXSmViMhI6NwZ9u+XXitZ4Y6ImtTj6datGyEhITc9FxISQrdu\n3Vxa/84770x2RGZKEib1pUuXUqhQoTRvL7NZa+OmG1DKadbCoEGwYgV8/LFMtpUVaFKPp2PHjixZ\nsoSIiAgADh8+zPHjx3nwwQfj+o0HBQVRrVo1FixYcMv6hw8fpmrMiITw8HC6du1KpUqVaN++fdzQ\nfJD+27HT9r7++usAfPDBBxw/fpzGjRvTuHFjQIbvnzlzBoBx48ZRtWpVqlatGjdt7+HDh6lUqRJP\nPfUUVapUoXnz5jftJ9aiRYuoU6cONWrU4KGHHuLUqVOA9IXv06cP1apVIyAgIG6ageXLlxMUFERg\nYGDcTUNGjhzJmDFj4rZZtWpVDh8+zOHDh6lQoQI9e/akatWqHDlyJNHjA9i8eTP16tUjMDCQ2rVr\nc/HiRRo0aHDTlML169dnZ0beFkZlGePGwaefyqjPfv2cjibzeG6dugNz7xYuXJjatWuzbNky2rVr\nR0hICJ07d8YYQ65cuZg3bx4FChTgzJkz3H///bRt2xaTRB+njz/+mDx58rBv3z527dp109S5o0eP\npnDhwkRFRdG0aVN27drFc889x7hx41izZg1FE4xs2Lp1K1OmTOGXX37BWkudOnVo2LAh/v7+HDhw\ngJkzZ/L555/TuXNn5s6dS48ePW5av379+mzcuBFjDJMmTeJ///sfY8eO5c0336RgwYLs3r0bkDnP\nQ0NDeeqpp1i3bh1ly5Z1aXreAwcOMG3aNO6///4kj69ixYp06dKFWbNmUatWLS5cuEDu3Ll58skn\nmTp1KuPHj+f333/n6tWrBGbULWGUxwgNhcKFwc8vY7Y/b57MZd6pk8ykmJVoST2B+FUw8aterLW8\n+uqrBAQE8NBDD3Hs2LG4Em9i1q1bF5dcAwICCAgIiHtt9uzZBAUFUaNGDfbs2ZPoZF3xrV+/nvbt\n25M3b17y5ctHhw4d+PHHHwEoW7Ys1atXB5Ke3vfo0aO0aNGCatWq8d5777Fnzx4AVq1addNdmPz9\n/dm4cSMNGjSgbNmygGvT8959991xCT2p4/vtt98oUaIEtWrVAqBAgQJkz56dTp06sXjxYq5fv87k\nyZPp3bt3ivtT3uf6dVizRhJt5cpyO7dSpWDwYOkr7s5au82bpetinTowbRpktXvZe25J3aG5d9u1\na8eLL77Itm3buHLlStxcNF9//TWhoaFs3bqVHDlyUKZMmTRNc/vnn38yZswYNm/ejL+/P717907T\ndmLFTtsLMnVvYtUvgwcPZsiQIbRt25YffviBkSNHpno/8afnhZun6I0/PW9qjy9Pnjw0a9aMBQsW\nMHv2bK8fRatuOHlS7su5ZAmsXCm9UHLkkKH2PXrAtm0waZIM7ClVSkrVXbpA7dppH+Tz11/SdbF4\ncZlwy5NmT8wsWewclrJ8+fLRuHFj+vbte1MDaey0szly5GDNmjX89ddfyW6nQYMGzJgxA4Bff/2V\nXbt2ATJtb968eSlYsCCnTp1i2bJlcevkz5+fixcv3rKtBx98kPnz53PlyhUuX77MvHnzePDBB10+\nprCwMEqWLAnAtGnT4p5v1qwZEydOjHt87tw57r//ftatW8eff/4J3Dw977Zt2wDYtm1b3OsJJXV8\nFSpU4MSJE2zevBmAixcvxs0d369fP5577jlq1aoVd0MO5X2io2UWw9dfl5kMS5SQOcc3bpRkPW+e\njM5cuRJefVV6o5w+LRNlBQXBxIlw//1yS7h//xu2bpXGTleFhUnXxatX5f6gt9+eccfqyVwqqRtj\nWgITAD9gkrX2nQSv3w1MBooBZ4Ee1tqjbo4103Tr1o327dvf1BOme/futGnThmrVqhEcHJziDR8G\nDBhAnz59qFSpEpUqVYor8QcGBlKjRg0qVqzIXXfdddO0vf3796dly5bceeedrFmzJu75oKAgevfu\nTe3atQFJgjVq1EjyTkoJjRw5kk6dOuHv70+TJk3iEvKIESMYOHAgVatWxc/Pj9dff50OHTrw2Wef\n0aFDB6Kjo7n99ttZuXIljz32GNOnT6dKlSrUqVOH++67L9F9JXV8OXPmZNasWQwePJjw8HBy587N\nqlWryJcvHzVr1qRAgQI657oXO3tWEveqVVLdUbeu1GU/8ggEBCRd8s6fHx5/XH7On5fS9axZ0sj5\nv//BvfdC48ZSwk/J5s0yJe6KFVCpknuPz5ukOPWuMcYP+B1oBhwFNgPdrLV74y3zDbDYWjvNGNME\n6GOtfSK57erUuyrW8ePHadSoEfv37ydbEhWgOvWu59q/X6o8/v4b3ntP6rPT+xH984+U7GfNcr2/\nRM6cMpPiE8lmHu/njql3awMHrbV/xGwwBGgHxG/dqwwMifl7DTA/beGqrGb69OkMHz6ccePGJZnQ\nledatgy6doVcuaQhtF4992y3SBHphpiVuiK6iyv/RSWBI/EeH415Lr6dQIeYv9sD+Y0xt5yrjTH9\njTFbjDFbQkND0xKv8jE9e/bkyJEjdOrUyelQVCpYC2PHQuvWUge+ebP7ErpKH3cVjV4CGhpjtgMN\ngWNAVMKFrLWfWWuDrbXBxYoVS3RDOiJRJaTfCc9y7Zo0gL70ErRvL10SfWUyLF/gSlI/BtwV73Gp\nmOfiWGuPW2s7WGtrAMNjnkv1pCV58uTh5MmT+k+s4kRHR3Py5EmuX7/udCgKOHVKpqGdOlV6ucye\nDfF6tCoP4Eqd+magvDGmLJLMuwKPx1/AGFMUOGutjQaGIT1hUq1cuXLs27eP48ePJzlSU2U9169f\n5++//wbQencHbd8O7drBmTOSzLXGzDOlmNSttZHGmEHACqRL42Rr7R5jzBvAFmvtQqAR8F9jjAXW\nAQOT3GAycubMSenSpZkxYwZ+fn43DaxRWdulS5coWLAg+fPndzqULGnOHOjVS4b2r18v/cqVZ0qx\nS2NGSaxLY6wTJ06wfv16Ll++nMlRKU9kjKFw4cI0atRIk3omCg+HXbvg22+lz3jduvL3HXc4HVnW\n5o4ujZmuRIkS2htCqUx04YL0B9+2TX62b4d9+yAqprtD797wySegF8+ezyOTulIqY0REwJ9/wu+/\nw969NxL4gQM3lilRQqpXHn1UfgcFwd13OxezSh1N6kr5mMhImdjqwIEbP7//Lr8PH755RsSyZSVp\n9+olv2vU0OoVb6dJXSkf8eefMofK1q0y1W2s/PmhfHmoVUuG8JcvLz8VKoDOn+Z7NKkr5QN274YW\nLWSGwiFD4L77biTv4sXTPpWt8j6a1JXychs2yGyIefLAjz9ClSpOR6ScpCM5lPJiy5fLDZWLFoWf\nftKErjSpK+W1Zs6UKW8rVJABQWXKOB2R8gSa1JXyQhMnSqNnvXrwww9Sb64UaFJXyqtYC2+8AYMG\nSSl9+XIoWNDpqJQn0YZSpbxEdDS88AJ8+KH0K580CbLrf7BKQEvqSnmB69flNm0ffihdFidP1oSu\nEqdfC6U83JUrMs3t0qXw9tswdKj2O1dJ05K6Uh7q8mV4/3249165F+inn8KwYZrQVfK0pK6Uh7lw\nAf7v/2DcOAgNhcaNISQEGjRwOjLlDTSpK+Uhzp2DDz6ACRPk75YtYcQIeOABpyNT3kSTulIOCw2V\nUvnEiXDxokx5O3w4BCd5GwSlkqZJXSmHHD8OY8bIzSeuXoXOnSWZV6vmdGTKm2lSV8oBa9dC69Zy\ny7gePaQBtEIFp6NSvkCTulKZbOVKaNdOblCxcCGUK+d0RMqXaFJXKhMtWQKPPQYVK0pyL1bM6YiU\nr9F+6kplknnzoH17qFoVVq/WhK4yhiZ1pTLBrFkyKrRmTVi1CgoXdjoi5as0qSuVwb78Uu4dWq8e\nfPcdFCrkdETKl2lSVyoDTZokMyo2aiRD/fPndzoi5es0qSuVQSZOhKeekhtCL14MefM6HZHKCjSp\nK5UBxo2TG1m0bQvz50Pu3E5HpLIKTepKudl//wv/+hd07Ahz5sBttzkdkcpKNKkr5Ubvvw+vvioN\nozNnQo4cTkekshodfKSUm2zcCK+8IhNyTZ8Ofn5OR6SyIi2pK+UG589Dt25QsiRMmaIJXTnHpaRu\njGlpjPnNGHPQGDM0kddLG2PWGGO2G2N2GWNauT9UpTyTtdC/Pxw5Ijez0H7oykkpJnVjjB8wEXgY\nqAx0M8ZUTrDYCGC2tbYG0BX4P3cHqpSn+uwz+OYbGD0a7r/f6WhUVudKSb02cNBa+4e1NgIIAdol\nWMYCBWL+Lggcd1+ISmWMefOga1e5SUVa7d4NL7wAzZvDyy+7Lzal0sqVhtKSwJF4j48CdRIsMxL4\nzhgzGMgLPJTYhowx/YH+AKVLl05trEq5zeHDMtLz4kXYskVGe5Yvn7ptXL4MXbpAwYLSMJpNW6iU\nB3DX17AbMNVaWwpoBXxpjLll29baz6y1wdba4GI6RZ1ySHQ09O4tf4eEQFgY1K0LGzakbjvPPw/7\n98NXX0Hx4m4PU6k0cSWpHwPuive4VMxz8T0JzAaw1v4M5AKKuiNApdztgw/kzkPjx0tJ++efwd8f\nmjSBuXNd28bMmfDFFzB0KDyU6HWpUs5wJalvBsobY8oaY3IiDaELEyzzN9AUwBhTCUnq6aipVCpj\n7N0ribhNG+jTR567915J7EFBMj3u++9Lj5akHDoETz8tsy6OGpU5cSvlqhSTurU2EhgErAD2Ib1c\n9hhj3jDGtI1Z7F/AU8aYncBMoLe1yf1bKJX5rl+Hnj1lpsTPPwdjbrxWtCh8/z106ABDhkjVSlTU\nrduIiJDGVT8/mDFDR4wqz+PSiFJr7VJgaYLnXov3917gAfeGppR7jR4NW7fKfCyJ1YHnzg2zZ8uo\n0LFj4e+/JXHnyXNjmWHDpGF17ly4++7Mi10pV2l7vcoSNm+Gt96CHj3kHqFJyZYNxoyReveFC6Fx\nYzh9Wl5bskRmXxw4UEr0Snki41QtSXBwsN2yZYsj+1ZZS3i41JdfvAi//ur6iM8FC2Tof4kScrOL\nTp1kGoBffoFcuTI2ZqWSYozZaq0NTup1Lakrn/fqq9L1cMqU1A3hb9cOfvhBTgZNmsjJYdYsTejK\ns2lSVz5tzRrpujhwIDRrlvr1a9eW2RebNoWpU6FiRbeHqJRbafWL8llhYRAQIDep2L5dbyenfENK\n1S86n7ryWS++CEePwk8/aUJXWYdWvyiftGCB1KEPG6YzJ6qsRZO68jmnT8NTT0H16vDaaykvr5Qv\n0eoX5VOOHJEh/GFhMkI0Z06nI1Iqc2lSV14vIgIWLZIJtlaskFkYJ0yAatWcjkypzKdJXXmtffsk\nkU+fLje6KFlS+qT36QP33ON0dEo5Q5O68iqXLsn8LF98IfOfZ88ObdvCk09CixZ6w2elNKkrjxcW\nJt0S58+XecwvXZJBQO+9B088oTeoUCo+TerK44SGwvr1sG6d3Mxi506pJ8+TR25q8eSTMpd5/Klz\nlVJCk7py3LFjksBjf/buledz55bbzL32GjRoAHXq3DwNrlLqVprUlSOuX5d7e44ZcyOJ588P9etL\nlUqDBhAcrF0SlUotTeoqU129KiM9330X/voLatSQ28c1aACBgdrQqVR6aVJXmeLKFfjsM2ncPH5c\nhu7/3//Bww9r3bhS7qRJXWWoCxckeY8bJw2gjRrBl1/KHYU0mSvlfprUVYY4d05uCTdhgvzdsiUM\nHy515kqpjKNJXbndwoVyL9CLF+XuQSNGSKOnUirjaVJXbnX+vMyQeM89Mnw/IMDpiJTKWjSpK7f6\nz3/gzBlYtkwTulJO0PnUldts2yaNogMGQFCQ09EolTVpUlduER0Nzz4LRYvCW285HY1SWZdWvyi3\n+OIL+OUXqUcvVMjpaJTKurSkrtLtzBkYOlRGhfbo4XQ0SmVtmtRVug0bJtPjTpyoA4qUcpomdZUu\nGzfCpEnwwgtQtarT0SilNKmrNIuKksbRO++E1193OhqlFGhDqUqHjz+G7dth1iyZNlcp5Twtqas0\nOXVKhv83awadOjkdjVIqlktJ3RjT0hjzmzHmoDFmaCKvv2+M2RHz87sx5rz7Q1We5OWXITwcPvpI\nG0eV8iQpVr8YY/yAiUAz4Ciw2Riz0Fq7N3YZa+2L8ZYfDNTIgFiVh1i7VqbPHT4c7rvP6WiUUvG5\nUlKvDRy01v5hrY0AQoB2ySzfDZjpjuCU57l+HQYOhLvvhldfdToapVRCrjSUlgSOxHt8FKiT2ILG\nmLuBssDqJF7vD/QHKF26dKoCVZ5hwgTYswcWLNCbQCvlidzdUNoVmGOtjUrsRWvtZ9baYGttcLFi\nxdy8a5XRjh6FkSOhdWto29bpaJRSiXElqR8D7or3uFTMc4npila9+KTr12HwYOmb/sEHTkejlEqK\nK0l9M1DeGFPWGJMTSdwLEy5kjKkI+AM/uzdE5bRNm+TORfPnw6hRULas0xEppZKSYlK31kYCg4AV\nwD5gtrV2jzHmDWNM/IvwrkCItdZmTKgqs124AM89B/ffD//8A/PmwSuvOB2VUio5Lo0otdYuBZYm\neO61BI9Hui8s5bQFC6SXy/Hj8nv0aChQwOmolFIp0RGl6ibHjkGHDvDoo1C4MGzYAB9+qAldKW+h\nc7/4oCtX4OGHITJSbitXo4b8rlwZcuZMfJ2oKPjkE5lG9/p1+O9/4V//ghw5Mjd2pVT6aFL3QW++\nCevWQd26MHWqDOUHSejVqt1I8kFB8vjQIejfX6bRfeghSe7lyjl6CEqpNNKk7mN274YxY6BPH5g8\nWe4devCg3BR6+3b5/e23Mgc6QLZsMneLv78M/e/eXedyUcqbGac6qwQHB9stW7Y4sm9fFR0N9evD\ngQOwfz8UKZL4ctbC33/fSPIREfDSS3LTaKWUZzPGbLXWBif1upbUfcjnn8PPP8O0aUkndJCS+N13\ny8+jj2ZefEqpjKe9X3zEyZNy8+fGjeGJJ5yORinlFE3qPmLIEOn18sknWieuVFamSd0HrFgBM2fK\nVLg6v7lSWZsmdS935QoMGCDJfOgt96RSSmU12lDq5d56C/78E9asgdtuczoapZTTtKTuxX79Fd57\nD3r3hkaNnI5GKeUJNKl7qehoeOYZKFhQErtSSoFWv3itL76An36CKVN00JBS6gYtqXuhU6dkXvOG\nDaFXL6ejUUp5Ek3qXkj7pCulkqJJ3ct89x3MmCFT5Fas6HQ0SilPo0ndi4SHw7PPap90pVTStKHU\nS1gLzz8vc5+vXg25cjkdkVLKE2lJ3Uu8+abMwhg7aZdSSiVGk7oXmDQJXn8devaEt992OhqllCfT\npO7hFi2Cp5+GFi0kuWtvF6WS4NANfzyNJnUPtnEjdOki9xKdM0dvAq1Ukg4elBvrfvqp05E4TpO6\nh9q/Hx55BO68E5YsgXz5nI5IKQ8VEQFdu8rMds89J/dozMI0qXug48ehZUvw85O50m+/3emIlPJg\nw4bB1q3Sk6BYMUnwFy86HZVjNKl7mLAwaNUKzpyBpUvlilIplYQlS2DcOBg4EPr1k5F5hw7JgI4s\nWseuSd2DXLsGHTrAnj0wdy4EJ3m/cKUUx47J5EeBgTBmjDzXoIF0FfvqK5g+3dn4HKJJ3UNER8v3\nc/VqmYGxRQunI1LKg0VFQffucPUqzJp182i84cNltrtnn4XffnMuRodoUvcQL70k383//lf6o2cJ\nkZHQvDksWOB0JMrbvPUWrF0LEydChQo3v+bnB19/DXnyQOfOkvgzkrUwYgQ0bSqNtU6z1jryU7Nm\nTavEe+9ZC9YOHmxtdLTT0WSiFSvkwJs0cToS5U1++MHabNmsfeKJ5JdbvFi+XwMHZlwsUVGyfbA2\nRw5r/f2tXbo04/ZnrQW22GRyq5bUUyE6Gh5/HMaPd982x4+Hl1+Gjh3h/fez2OCikBD5vXattAwr\nlZIzZ6TapVw5KaUn55FHZJ7qiRNh3jz3xxIdLSMDJ06Uf+J9+6B0adnvyJHyuhOSy/gZ+eONJfU1\na+SEDNa+/HL6S9XvvCPbaoNepL8AABn1SURBVN/e2mvX3BKi97h61dqCBa2tUUPehMmTnY5Iebro\naGtbt7Y2Z05rt21zbZ1r16wNDra2UCFrDx92XyzXr8uVAlg7YsSNZHD5srW9esnzLVtae+aM+/YZ\ngxRK6i4lYKAl8BtwEBiaxDKdgb3AHmBGStv0xqTeq5e1BQpY27+/vHN9+8pnm1rR0daOGiXb6NrV\n2ogIt4fq+RYskDdg6VJr777b2kcecToizzVlirXNm1s7daq1ly45HY1z3n9fvjMffJC69Q4etDZ/\nfmvr1nXPP1tEhLVdukgsb7556+vR0dZ++qmcfO6+29rNm9O/z3jSndQBP+AQcA+QE9gJVE6wTHlg\nO+Af8/j2lLbrbUn94kVr8+a19qmn5DN77TV59x591NrwcNe3Ex1t7auvyro9e1obGZlxMXu0bt2s\nLVJE/kFefFH+AcLCnI7K8yxdKvXH+fLJlyZ/filVbNqUtRpgtmyROuu2bdN23DNnyvv36qvpi+Pa\nNbm0BmkMS86mTdaWLi3f7c8+c9vn5Y6kXhdYEe/xMGBYgmX+B/RLaVvxf7wtqU+dKu/WTz/deG7C\nBHmucWPX8lF0tLVDhsg6/fpJG0uWdOmStXnySHKy1toff5Q3ZcYMZ+PyNDt2SDKvUcPaCxesXbdO\nLhdz55b3q1o1+RJmwCW+RwkLs7ZcOWtLlUrfsT75pLXGWLtyZdrWDw+XK8rUXC2EhspVFljbp4+1\nV66kbd/xuCOpdwQmxXv8BPBRgmXmxyT2n4CNQMskttUf2AJsKV26dLoPLjM1amRt+fK3nmy/+sra\n7NmtrVnT2tOnk14/fiP5oEFZOKFba+2sWfJGrF4tj6OirL3jDms7dnQ2Lk9y7JgksZIlrT169ObX\nzp+39pNPpK4YpCTYpYskK1/7YkVHW/v443K18uOP6dvW5cvWVqpkbfHi1p48mfp1mzWTk8Knn6Zu\n3cjIG5f21atbe+hQ6tZPILOS+mJgHpADKAscAQolt11vKqn/8Ye8U6NHJ/764sXW5spl7X33WfvX\nX7e+HhUlJXOw9l//SnBiiC2+jx/veZXr0dFy8HPmWDt8uLXt2klrcXq1by9JPH7d0zPPSOk9vSWZ\nyEh5s/v2tfajj6zdsMH76qEvXpTSeb58UlpPzs6d1j73nHSlA2vLlJEGm7//Tn8cV6/KCbhLF6n+\nyCyxVyXjx1vbqZNNsu46LXbtkn/WgABrX39d2nb+/jv5qpGLF6VUly2bXLKn1ZIl8jkVKmTtsmVp\n3kxmVb98AvSJ9/h7oFZy2/WmpD5ypJygk/s/+fFH6cxRqpS1e/feeD4yUurOQfLiLd+drVttXJea\nSpWk77YTIiOt3bfP2q+/ljNP48by5YuNzc9PLvtr1Ehf3WBYmLW33SaJKL6VK2U/8+al7zgWLbJx\ndc+xsWfLJu9t9+7Wjh0rJ6Zz59K3n4wSGWltmzYS85Ilrq8XHi71xk2byjEbI70v5sxJfdeqXbus\nff55afOIfQ/btEndNlwVGmrtd99Z++67cvIoX/7GPkFO/k8/7d7Gp9mz5fuQLduN/RQtKtUk//63\nnMgOHJDS2Pnz1tarJ99/d1QP/vGHtbVrW7t2bZo34Y6knh34I6YEHttQWiXBMi2BaTF/F40pqRdJ\nbrvektSjoqwtW9bahx5KedmdO+U7WKSItb/8IgXvrl3lXX7jjSRWevllqb/58kupNwRpDDp40K3H\nkaR166x94AEpJcd+wW+7zdpataTO+5NPpMHnyhXpdgjpO/FMny7b2LDh5ucjIqQUk9KAkpQ0ayZV\nFhERchaeP19KZG3ayPPxE8Y990idmCddIb3wgsT20Udp38Yff1j7n//cON5ixeRqcM+epNcJC5PG\nvNq1bdxAmk6d5LP+978lASasBkqr69clUZcuffPnUaaMXMW9+aac0I4fd8/+knLpknwPJ06U+vYa\nNeS4Y+PJn1/ew+zZ5eToLulsMHVXl8ZWwO8xvWCGxzz3BtA25m8DjIvp0rgb6JrSNr0lqf/wg7xL\nX33l2vIHD0quyJtXBkqCFEISFRUlX+xWreTx1avSeT1vXqknHTZMLv0yyrFjUkIpXVpKzlOnypkp\nqSR37Zp8yRs3Tvs+W7WSbl6JfbF79ZKrg7R22t+zJ/l6MmutPXXK2uXLrX377Ru9GPr184yeJB9+\nKPG88IJ7thcZKb1nOnSQxATSrW/SJPleRUdbu369tb173zipV6kiXQdDQ29s59ChFEomqfTNNzdK\n///7n7WrVln7zz/u2XZ6XbsmfeAnTbL22Wel9J6aK6ZM4JaknhE/3pLUe/eWE/bly66vc/y4dEwA\n6ZyQpJ9+koWmT7/5+WPHbgxsuPNOKcW7O+lERspZJ0+em+uLUjJ2rMS1cWPq93nmjCSXV15J/PWF\nC2Xby5enftvWWjtggFxlJNdindDw4SmceTPJ4sVSGm7bNmP6uZ46JV3wKlaU482Xz9p7773xd79+\n8pkm9T176CE5GbsjtgcflMvfLNufN300qadDbN/0fv1Sv+6FC1JdnqzBgyUJJdUf8uefb/RwqFvX\nvYMY3nxTtvvFF6lb78IFqSZp3z71+/zsM9lnUqMBw8MlwcR2dUyNc+fkBNW7d+rWi4q6UUf2zTep\n3687bN8uX7SgoIxv1I2OlsJEnz5SVTV5smtXg7E9ltLRwGetlc8erB0zJn3bycI0qadDbN/09esz\nYOORkVIB36FD8stFRck/XvHi0vjVv79U06THunVSKnz88bRdAfznP/LGpKaEb61cGdx3X/L77NLF\n2ttvT30pLvYKIsUzaSLCw6UxLFcuOZFmpiNH5GqsVCm5QvNU165J3XxK39eU9OkjJ9+zZ90TVxak\nST0dGjWSK9QMqW5dvVre/tmzXVs+LOzGyKVWrVI3jDW+M2ckgZQrl/YRnKdPS0+YPn1cX+f4cTkp\n/ec/yS8XWyJMTe+AyEhpyKhf3/V1Ejp9WrZRrJg0NGaGixel33K+fNKW4eleekmqz06cSNv6oaFy\nZfrMM+6NK4tJKalnTzjBV5Z06BAsWgTPPx83TeLhw/DDDzJtc4bMnBgSAnnzyoxurihQAMaOlbmj\nn34a2raF+fNlzmhXWQt9+8KpU/Dzz7LNtChWTG4d9sknMGoU3HVXyuvMmSP779o1+eVatYLbboNv\nv5W72Lhi6VL44w945x3Xlk9MsWKynbp1JYYNG8DfP/XbWboUFi927VZqO3bA7t2yfEBA6veV2Z56\nSu4wNHUqDB2a+vU//1xu7zV4sNtDU/Ekl/Ez8sejSup9+kjpcNOmuKdGjZKCZWKDidItIsLawoVl\n/pO0mDJFgmvYMHW9Y2LnNXj//bTtN77Dh6Xv7osvurZ8vXrSeuyKtm2tvesu1y+RHnpIrj7c0TVx\nzRrp1takSep64ezfb+3DD8v7W6CAVCGl9HPnnalv03Baw4ZylZfakasREfIZudI3WCULrX5JwfXr\nkmBjx+/bG33TmzbNoH0uXSr7W7Ag7dv4+mtJqvXqyQCJlGzdKt0kW7d2X31Sjx7SwJdSd7S//rIp\ndjWML7YxI95JNkmx3Rjfftu1bbti2jTZZt++Kb9X58/LYK3s2SWZjx3r2/Mof/WVvDerVqVuvdmz\nZb2FCzMmrixEk3pKVq2ycSPXihSx9to1u3atPPXllxm0z549Zfhpehs858yRZFKrVvINTxcuyEi9\nkiVv7n+cXrt2WZf6L8fe2snVAVX//CPHNXRoyss+84zU07rzuKy90Ric1MkiKkpK2bffLldNTz6Z\n+vlEvFF4uPR+6tIldevVry9tFtqNMd00qafk2Wel0S92QMS8ebZPH+mbniG9y8LDZeOpaWRMzsKF\nUgKvXj3xxBYdLSXqbNnSNTQ5Sa1by8kwuTerZk058aRGs2aJz6AW39mz0pOib9/UbdsVsRNJgbUh\nITe/tmFDxnU19QbPPy9VVK6OB4jtxjhuXMbGlUVoUk9OVJS1JUpIN63r160tXtxeb9Pe5s0rBa8M\n8e23Nt1D7RNatky641WtemtpMbYqY9Qo9+0vvvXrZftJTUX6++/y+tixqdvuJ5/Iert3J73MmDGy\nzPbtqdu2q8LDZQqF226Tvt3HjskJMiMHhXmDX3+1qeprHtuN0VPn2/EymtSTEzui8+uv5fGQITbS\nL4ctzJl0z/KZpM6dZWh+Wm6ZlJzvv5d/nAoVbszRsW+fPNeoUcZe9tavL1MNJNZQGTvI6ciR1G3z\nxAmp1hg5MvHXIyNlrpAHH0x9vKkRGioNg/7+mTd9gzeoV0++aymd1E6flpPigAGZE1cWoEk9Of/6\nl1xGxjY07thhLdjXik7MmAJY7M0hMuoLvm6d9HkuV87a336T6UWLFs34QS2xd21PON2BtTKXSFoT\nb/36cgyJib0dXmaMAv3tN2mPaNcu8yZa83RTpliXxhOMHi3LJTeZmEoVTepJiY6Wkl7sZFrW2j//\ntHYHAfZoqdoZs8/YW2plRN12rJ9/lkbY2NnmFi/OuH3Fio6Wqp8qVW7u6rZ7t03XjIOx96Q8cODW\n15o2lS5y7r7iSUpWrGZJzuXL8j3r0SPpZSIi5GTYrFnmxZUFpJTUsznXQ95hO3bICKMOHeKemj4d\nvqQnJY9ugv373b/PkBC4806oX9/92451//2wejUUKQLDhrk+uCk9jIF//xv27IElS248HxIC2bJB\nx45p22779vL7229vfn7PHvj+exg4ELJn0vi5DBmB5sXy5IHu3eGbb+Ds2cSXmTcPjh2D557L3Niy\nuuQyfkb+OF5SHzFCeoTEtOBHR0uPq071j8vz6b1BbULnzkl9rKuDddIrs29rFhEhs/jVrStvZnS0\nzLGQ3sEmwcHW1qlz83NPPy0Nw+7uxqhSJ6a6MsmpSB94IG0DlVSy0JJ6EubOhYYNZXg4sH69jDRv\n+3QJaN4cvvwSoqPdt7/58yEiArp0cd82k5Mtkz/aHDngpZdk+oH162HbNjh4MOVpAVLSoQP88gsc\nPSqPz52TS6ru3aFo0fTHrdIuMBBq1YLPPrt1WoRt2+Cnn2DQoMz/LmZxWfPd3rdPfuJVvUydCvny\nxVzx9+wJR47A2rXu22dICJQpA7Vru2+bnqZvX0m077wjx5sjx40qlLSK/YzmzZPfX3wB4eE6f4in\neOopqQ7buPHm5z/8UOY26tPHmbiysKyZ1GPraGMSzuXLMHs2dO4s30MefVQmu5o+3T37Cw2FVauk\n1OrLdbN58sikaEuXwqRJ0KIFFC6cvm1WqABVqshnFhUFH30kV1iBge6JWaVP165SGvr88xvPnT4N\nM2ZA795QsKBjoWVVWTep338/lCyJtfDee3DpknwHAcidGzp1kpkFL19O//7mzpWElN6qCG8wcKD8\nk58/777j7dAB1q2DyZPhr7+0lO5J8ueHbt3kyiwsTJ77/HOpahw0yNnYsqisl9QPH5b6vg4duHQJ\nHn9cZo997LEEnVJ69pRMH3vZnx4hIVCxondMr5pe/v7yz1ywoEwP7A6PPSbtG88/L9P8tmvnnu0q\n9+jfX6rEZsyA69fh//5P2qUqVnQ6siwp6yX1mKqXQ4EdqFNHql3eflt+31QzUr++1IGntwrm+HEp\nZfp61Ut8b70lrc7587tnewEBcM89kjgysxujck3NmlC9ujSYzp0r33ntxuiYLJnUz5cJpPpj5QgN\nhe++k+7ctzTQZ8sGTzwhdeHHjqV9f998Iz0DMqvXiyfw80t/XXp8xsglfv78cnMO5VmMkQbTHTvg\nlVegXDl4+GGno8qyslRSjzxyguifNjDucAeqVpVamKZNk1nhiSckIX/9ddp3GhIipRi9FE2f116D\n33+XQVXK83TvLm1RR45Im4d2Y3RMlnnnT56ED5rMJxuWnF0fY+1aKFUqhZXKl4d69WDaNNduT5bQ\nn39KV6+s0ECa0XLmhDvucDoKlZSCBSWxFywYr8eBckKWSOrr10NQEFT/Yy4X7riPETMqkzOniyv3\n7Al790qxPrVmz5bfWanqRWVdEybAr79qN0aH+XRStxbefx8aNYKSuf6hsfmBAn0eS12DZefOUkpM\nS4NpSAjUqSMNrkr5ujx5XLj8VRnNZ5P62bNSQB4yBNq0gbUvLcJERd00itQl/v7SNS+2u5ar9u+X\nhiOtelFKZSKfTOpLl0LVqtLF/N13pRdjnmVzoXRp6X6VWj17wpkzsHy5a8uvWiV9q/38ZBCTUkpl\nEp9K6hcuSM+qRx6RKUg2bZIeVubSRem72KFD2vqKt2wpE3+lVAXzxx8y9UCzZtKnesECKFkybQej\nlFJp4DNJffVqqFZNRpIPGwabN0ONGjEvLlkiw5ZTW/USK0cOGXq6cGHic0dfugQjRkDlyrByJYwe\nLY2rmTGXuVJKxeP1Sf3KFRm81rQp5Mols32+/Tbcdlu8hb79FooXl+6JadWzp5wYYnu0gLTEzpgh\nfdBHj5abQfz2G7z6qgSjlFKZzKuT+oYNMq7nww8lsW/fLvN03SQ8XCrZH31U6rjTqkYNmS0wtgpm\n2zZ48EHpm3vHHXI2+eorrW5RSjnKK5P6tWswdKjk1IgIqXqZMEF6VN3iu+9kpsW0Vr3EMkZK6z//\nLEPWg4NlhOOkSVJ5n56rAKWUchOXkroxpqUx5jdjzEFjzNBEXu9tjAk1xuyI+cmwCTq2bZMOLO++\nC08+Cbt2QePGyazw7bdQqFAKC7moe3cZ/jxnDrz4Ihw4IEHokGillIdIcbo7Y4wfMBFoBhwFNhtj\nFlpr9yZYdJa1NsMnUN64UdoqlyyBVq1SWDgiQho327aVxs70KllSGkJLlpSbNyillIdxZQ7T2sBB\na+0fAMaYEKAdkDCpZ4pnnpGOKIUKubDwDz/IzRoee8x9ATRp4r5tKaWUm7lSb1ASOBLv8dGY5xJ6\nzBizyxgzxxhzV2IbMsb0N8ZsMcZsCQ0NTUO4UtPhUkIHqXrJm1f6jSulVBbgrsrgRUAZa20AsBKY\nlthC1trPrLXB1trgYsWKuWnXSfjlF5g1S+pocufO2H0ppZSHcCWpHwPil7xLxTwXx1r7j7X2WszD\nSUAaxuK7ibXw8cfSNaZQIblXnVJKZRGuJPXNQHljTFljTE6gK7Aw/gLGmBLxHrYF9rkvxFS4cgV6\n9YJnn5Uql61boVIlR0JRSiknpNhQaq2NNMYMAlYAfsBka+0eY8wbwBZr7ULgOWNMWyASOAv0zsCY\nE3fwoPRF//VXeOMNGD5cuxoqpbIcY9NyRx83CA4Otlu2bHHPxhYskIFB2bPLsP0WLdyzXaWU8jDG\nmK3W2uCkXvfuomxkpMze9eijcN99MjJJE7pSKgtzpZ+6Zzp9Wobrr14N/fvLPAE6iZZSKovzzqS+\ncaPMiPjPPzBlit7oVimlYnhf9cu0adCggcyt+/PPmtCVUioe70vq5ctD69awZYvMu6uUUiqO91W/\n1Ksnw/+VUkrdwvtK6koppZKkSV0ppXyIJnWllPIhmtSVUsqHaFJXSikfokldKaV8iCZ1pZTyIZrU\nlVLKhzg29a4xJhT4K42rFwXOuDEcT+Brx+RrxwO+d0y+djzge8eU2PHcba1N8n6gjiX19DDGbElu\nPmFv5GvH5GvHA753TL52POB7x5SW49HqF6WU8iGa1JVSyod4a1L/zOkAMoCvHZOvHQ/43jH52vGA\n7x1Tqo/HK+vUlVJKJc5bS+pKKaUSoUldKaV8iNcldWNMS2PMb8aYg8aYoU7Hk17GmMPGmN3GmB3G\nmC1Ox5MWxpjJxpjTxphf4z1X2Biz0hhzIOa3v5MxpkYSxzPSGHMs5nPaYYxp5WSMqWWMucsYs8YY\ns9cYs8cY83zM8175OSVzPF77ORljchljNhljdsYc06iY58saY36JyXmzjDE5k92ON9WpG2P8gN+B\nZsBRYDPQzVq719HA0sEYcxgIttZ67YAJY0wD4BIw3VpbNea5/wFnrbXvxJx8/a21/3YyTlclcTwj\ngUvW2jFOxpZWxpgSQAlr7TZjTH5gK/Ao0Bsv/JySOZ7OeOnnZIwxQF5r7SVjTA5gPfA8MAT41lob\nYoz5BNhprf04qe14W0m9NnDQWvuHtTYCCAHaORxTlmetXQecTfB0O2BazN/TkH84r5DE8Xg1a+0J\na+22mL8vAvuAknjp55TM8XgtKy7FPMwR82OBJsCcmOdT/Iy8LamXBI7Ee3wUL/8gkQ/tO2PMVmNM\nf6eDcaPi1toTMX+fBIo7GYybDDLG7IqpnvGKaorEGGPKADWAX/CBzynB8YAXf07GGD9jzA7gNLAS\nOASct9ZGxiySYs7ztqTui+pba4OAh4GBMZf+PsVKHZ/31PMl7mOgHFAdOAGMdTactDHG5APmAi9Y\nay/Ef80bP6dEjserPydrbZS1tjpQCqmZqJjabXhbUj8G3BXvcamY57yWtfZYzO/TwDzkg/QFp2Lq\nPWPrP087HE+6WGtPxfzDRQOf44WfU0w97Vzga2vttzFPe+3nlNjx+MLnBGCtPQ+sAeoChYwx2WNe\nSjHneVtS3wyUj2kNzgl0BRY6HFOaGWPyxjTyYIzJCzQHfk1+La+xEOgV83cvYIGDsaRbbOKL0R4v\n+5xiGuG+APZZa8fFe8krP6ekjsebPydjTDFjTKGYv3MjHUL2Icm9Y8xiKX5GXtX7BSCmi9J4wA+Y\nbK0d7XBIaWaMuQcpnQNkB2Z44/EYY2YCjZBpQk8BrwPzgdlAaWSK5c7WWq9ofEzieBohl/QWOAw8\nHa8u2uMZY+oDPwK7geiYp19F6qG97nNK5ni64aWfkzEmAGkI9UMK3LOttW/E5IkQoDCwHehhrb2W\n5Ha8LakrpZRKmrdVvyillEqGJnWllPIhmtSVUsqHaFJXSikfokldKaV8iCZ1pZTyIZrUlVLKh/w/\nDrPgBFMoYQwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs3AB0qC4-pD",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 RNN with LSTM\n",
        "Use glove embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qncKCWpn0dGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c6a39c8-73c0-47a0-91b9-91adeaec4426"
      },
      "source": [
        "vocabulary_size = 10000   #specify desired size of pre-defined embedding vocabulary \n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(documents)\n",
        "\n",
        "# integer encode the documents\n",
        "sequences = tokenizer.texts_to_sequences(documents)\n",
        "embeddings = pad_sequences(sequences, maxlen=50)\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('embeddings/gloVe.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9dnetgb5K1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------    \n",
        "# Make embeddings a numpy array for use in an RNN \n",
        "# Create training and test sets with Scikit Learn\n",
        "# -----------------------------------------------------\n",
        "RANDOM_SEED = 9999\n",
        "\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Define the labels to be used 500 negative (0) and 500 positive (1)\n",
        "thumbs_down_up = np.concatenate((np.zeros((500), dtype = np.int32), \n",
        "                      np.ones((500), dtype = np.int32)), axis = 0)\n",
        "\n",
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(embeddings_array, thumbs_down_up, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwKhqn6J5PAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c9c53429-99ba-4a37-c0df-db9006e3ab28"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 100, input_length=50, trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 50, 100)           1000000   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 46, 64)            32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 11, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               66000     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,098,165\n",
            "Trainable params: 98,165\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgIvReac5Vn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58964637-a9f3-433a-9e4c-faed29528b4b"
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/30\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.6964 - acc: 0.4725 - val_loss: 0.6947 - val_acc: 0.4700\n",
            "Epoch 2/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6913 - acc: 0.5325 - val_loss: 0.6911 - val_acc: 0.5900\n",
            "Epoch 3/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6882 - acc: 0.5375 - val_loss: 0.6886 - val_acc: 0.5850\n",
            "Epoch 4/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6756 - acc: 0.6675 - val_loss: 0.6761 - val_acc: 0.5900\n",
            "Epoch 5/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6503 - acc: 0.6212 - val_loss: 0.6584 - val_acc: 0.6000\n",
            "Epoch 6/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5819 - acc: 0.7075 - val_loss: 0.6811 - val_acc: 0.5900\n",
            "Epoch 7/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5543 - acc: 0.7063 - val_loss: 0.6444 - val_acc: 0.6050\n",
            "Epoch 8/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4847 - acc: 0.7787 - val_loss: 0.6880 - val_acc: 0.6050\n",
            "Epoch 9/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4697 - acc: 0.7863 - val_loss: 0.6509 - val_acc: 0.6250\n",
            "Epoch 10/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3643 - acc: 0.8425 - val_loss: 0.6959 - val_acc: 0.6250\n",
            "Epoch 11/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3154 - acc: 0.8612 - val_loss: 0.7441 - val_acc: 0.6050\n",
            "Epoch 12/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2751 - acc: 0.8875 - val_loss: 0.7795 - val_acc: 0.6300\n",
            "Epoch 13/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2374 - acc: 0.9088 - val_loss: 0.7642 - val_acc: 0.5950\n",
            "Epoch 14/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2339 - acc: 0.9075 - val_loss: 0.7947 - val_acc: 0.6050\n",
            "Epoch 15/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1801 - acc: 0.9350 - val_loss: 0.8173 - val_acc: 0.6250\n",
            "Epoch 16/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1383 - acc: 0.9475 - val_loss: 0.8218 - val_acc: 0.6150\n",
            "Epoch 17/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1575 - acc: 0.9363 - val_loss: 0.7972 - val_acc: 0.6200\n",
            "Epoch 18/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1157 - acc: 0.9475 - val_loss: 0.9037 - val_acc: 0.6350\n",
            "Epoch 19/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0951 - acc: 0.9700 - val_loss: 0.9210 - val_acc: 0.6100\n",
            "Epoch 20/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1366 - acc: 0.9525 - val_loss: 0.8540 - val_acc: 0.6050\n",
            "Epoch 21/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1151 - acc: 0.9625 - val_loss: 0.8459 - val_acc: 0.5850\n",
            "Epoch 22/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0852 - acc: 0.9725 - val_loss: 0.9937 - val_acc: 0.6350\n",
            "Epoch 23/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0830 - acc: 0.9700 - val_loss: 0.9226 - val_acc: 0.6350\n",
            "Epoch 24/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0812 - acc: 0.9700 - val_loss: 0.9310 - val_acc: 0.6450\n",
            "Epoch 25/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0365 - acc: 0.9900 - val_loss: 1.1755 - val_acc: 0.6450\n",
            "Epoch 26/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0752 - acc: 0.9662 - val_loss: 1.0874 - val_acc: 0.6450\n",
            "Epoch 27/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0698 - acc: 0.9738 - val_loss: 0.9749 - val_acc: 0.6050\n",
            "Epoch 28/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0702 - acc: 0.9775 - val_loss: 0.9454 - val_acc: 0.6050\n",
            "Epoch 29/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0711 - acc: 0.9763 - val_loss: 1.2381 - val_acc: 0.6450\n",
            "Epoch 30/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0655 - acc: 0.9775 - val_loss: 1.0644 - val_acc: 0.5750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-tiuXdt5ZhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "f9881031-7945-4253-d055-26c34ab92b82"
      },
      "source": [
        "score, acc = model.evaluate(X_train, y_train, batch_size=batch_size)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)\n",
        "\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "# Plot the accuracy curves for training and validation \n",
        "pyplot.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "pyplot.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "legend = pyplot.legend(loc='best', shadow=True)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 0s 174us/step\n",
            "Train score: 0.004202920012176037\n",
            "Train accuracy: 1.0\n",
            "200/200 [==============================] - 0s 186us/step\n",
            "Test score: 1.06438818693161\n",
            "Test accuracy: 0.575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUxoXIgRyEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdhxN7jF5sd9",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 RNN with LSTM\n",
        "Use gloVe embeddings, increase vocabulary size to 30,000\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsbgCbfX5rSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9da4656b-e7a6-4c1e-e5c4-bc8474dc864c"
      },
      "source": [
        "vocabulary_size = 30000   #specify desired size of pre-defined embedding vocabulary \n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(documents)\n",
        "\n",
        "# integer encode the documents\n",
        "sequences = tokenizer.texts_to_sequences(documents)\n",
        "embeddings = pad_sequences(sequences, maxlen=50)\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('embeddings/gloVe.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMjX97-35vPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------    \n",
        "# Make embeddings a numpy array for use in an RNN \n",
        "# Create training and test sets with Scikit Learn\n",
        "# -----------------------------------------------------\n",
        "RANDOM_SEED = 9999\n",
        "\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Define the labels to be used 500 negative (0) and 500 positive (1)\n",
        "thumbs_down_up = np.concatenate((np.zeros((500), dtype = np.int32), \n",
        "                      np.ones((500), dtype = np.int32)), axis = 0)\n",
        "\n",
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(embeddings_array, thumbs_down_up, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyhvpj0X6OYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "50d973c1-25b3-4542-efe0-76fa06a8220a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 100, input_length=50, trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 50, 100)           3000000   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 46, 64)            32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 11, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               66000     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 3,098,165\n",
            "Trainable params: 98,165\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nvl_nBv6RbE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ab8868b-bf3c-48e4-b9d0-a700a4fc616f"
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/30\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.6931 - acc: 0.5025 - val_loss: 0.6934 - val_acc: 0.4700\n",
            "Epoch 2/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6896 - acc: 0.5487 - val_loss: 0.6895 - val_acc: 0.6400\n",
            "Epoch 3/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6788 - acc: 0.6013 - val_loss: 0.6796 - val_acc: 0.6150\n",
            "Epoch 4/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6440 - acc: 0.6300 - val_loss: 0.6714 - val_acc: 0.5600\n",
            "Epoch 5/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6203 - acc: 0.6450 - val_loss: 0.6654 - val_acc: 0.5850\n",
            "Epoch 6/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6144 - acc: 0.6750 - val_loss: 0.6622 - val_acc: 0.5850\n",
            "Epoch 7/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5584 - acc: 0.7087 - val_loss: 0.6623 - val_acc: 0.5800\n",
            "Epoch 8/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5335 - acc: 0.7350 - val_loss: 0.7525 - val_acc: 0.5650\n",
            "Epoch 9/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4777 - acc: 0.7700 - val_loss: 0.7302 - val_acc: 0.5950\n",
            "Epoch 10/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4432 - acc: 0.7775 - val_loss: 0.7405 - val_acc: 0.5650\n",
            "Epoch 11/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4266 - acc: 0.8050 - val_loss: 0.7375 - val_acc: 0.6300\n",
            "Epoch 12/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3809 - acc: 0.8438 - val_loss: 0.7720 - val_acc: 0.6300\n",
            "Epoch 13/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4191 - acc: 0.8150 - val_loss: 0.6946 - val_acc: 0.6200\n",
            "Epoch 14/30\n",
            "800/800 [==============================] - 1s 997us/step - loss: 0.2747 - acc: 0.8912 - val_loss: 0.7792 - val_acc: 0.6050\n",
            "Epoch 15/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2480 - acc: 0.9050 - val_loss: 0.8337 - val_acc: 0.5950\n",
            "Epoch 16/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1998 - acc: 0.9312 - val_loss: 0.9389 - val_acc: 0.6000\n",
            "Epoch 17/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1639 - acc: 0.9363 - val_loss: 0.8859 - val_acc: 0.5900\n",
            "Epoch 18/30\n",
            "800/800 [==============================] - 1s 949us/step - loss: 0.1542 - acc: 0.9413 - val_loss: 0.9395 - val_acc: 0.5850\n",
            "Epoch 19/30\n",
            "800/800 [==============================] - 1s 964us/step - loss: 0.1308 - acc: 0.9537 - val_loss: 1.0266 - val_acc: 0.6050\n",
            "Epoch 20/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1606 - acc: 0.9387 - val_loss: 0.9114 - val_acc: 0.6350\n",
            "Epoch 21/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1176 - acc: 0.9575 - val_loss: 0.9348 - val_acc: 0.6200\n",
            "Epoch 22/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0710 - acc: 0.9838 - val_loss: 1.0454 - val_acc: 0.6000\n",
            "Epoch 23/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1058 - acc: 0.9612 - val_loss: 0.9550 - val_acc: 0.6150\n",
            "Epoch 24/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0815 - acc: 0.9713 - val_loss: 0.9099 - val_acc: 0.6250\n",
            "Epoch 25/30\n",
            "800/800 [==============================] - 1s 984us/step - loss: 0.0802 - acc: 0.9725 - val_loss: 0.9353 - val_acc: 0.6050\n",
            "Epoch 26/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0955 - acc: 0.9625 - val_loss: 0.8524 - val_acc: 0.6200\n",
            "Epoch 27/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0892 - acc: 0.9612 - val_loss: 0.9037 - val_acc: 0.6300\n",
            "Epoch 28/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0575 - acc: 0.9800 - val_loss: 1.0930 - val_acc: 0.6300\n",
            "Epoch 29/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0594 - acc: 0.9775 - val_loss: 0.8821 - val_acc: 0.6100\n",
            "Epoch 30/30\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0437 - acc: 0.9850 - val_loss: 1.1135 - val_acc: 0.6500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJvLrEaG6W8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "4911bec3-c522-4f84-d193-156ebcf2f180"
      },
      "source": [
        "score, acc = model.evaluate(X_train, y_train, batch_size=batch_size)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)\n",
        "\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "# Plot the accuracy curves for training and validation \n",
        "pyplot.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "pyplot.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "legend = pyplot.legend(loc='best', shadow=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 0s 179us/step\n",
            "Train score: 0.0021701662056148054\n",
            "Train accuracy: 1.0\n",
            "200/200 [==============================] - 0s 195us/step\n",
            "Test score: 1.113481764793396\n",
            "Test accuracy: 0.65\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5t1YHnuZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIYvSZE17M7D",
        "colab_type": "text"
      },
      "source": [
        "## modify model hyperparameter settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvsG87jMKaZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph() # Refresh graph to make output stable across runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPler3gOHzi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4985e49f-9c1c-43af-df6d-f7ea53b7debd"
      },
      "source": [
        "vocabulary_size = 30000   #specify desired size of pre-defined embedding vocabulary \n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(documents)\n",
        "\n",
        "# integer encode the documents\n",
        "sequences = tokenizer.texts_to_sequences(documents)\n",
        "embeddings = pad_sequences(sequences, maxlen=50)\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('embeddings/gloVe.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWiagsCSH5ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------    \n",
        "# Make embeddings a numpy array for use in an RNN \n",
        "# Create training and test sets with Scikit Learn\n",
        "# -----------------------------------------------------\n",
        "RANDOM_SEED = 9999\n",
        "\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Define the labels to be used 500 negative (0) and 500 positive (1)\n",
        "thumbs_down_up = np.concatenate((np.zeros((500), dtype = np.int32), \n",
        "                      np.ones((500), dtype = np.int32)), axis = 0)\n",
        "\n",
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(embeddings_array, thumbs_down_up, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo-lkXVSH_UL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0bc04096-c5d6-4695-95ca-36739b3dfbe8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 100, input_length=50, trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 100)           3000000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 46, 64)            32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 11, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               66000     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 3,098,165\n",
            "Trainable params: 98,165\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvR_uKPM6_2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.optimizers import adam\n",
        "\n",
        "# # compile model\n",
        "# opt = optimizers.RMSprop(lr=1e-5)\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer=opt,   \n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw49e2p-JG1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e149cd01-cb36-48b9-a20f-3777fcc8366c"
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='RMSprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/30\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.1317 - acc: 0.9487 - val_loss: 0.8539 - val_acc: 0.6200\n",
            "Epoch 2/30\n",
            "800/800 [==============================] - 1s 754us/step - loss: 0.1462 - acc: 0.9438 - val_loss: 0.8526 - val_acc: 0.6200\n",
            "Epoch 3/30\n",
            "800/800 [==============================] - 1s 735us/step - loss: 0.1256 - acc: 0.9600 - val_loss: 0.9065 - val_acc: 0.6050\n",
            "Epoch 4/30\n",
            "800/800 [==============================] - 1s 755us/step - loss: 0.1306 - acc: 0.9500 - val_loss: 0.9490 - val_acc: 0.6050\n",
            "Epoch 5/30\n",
            "800/800 [==============================] - 1s 723us/step - loss: 0.1064 - acc: 0.9587 - val_loss: 0.9655 - val_acc: 0.5900\n",
            "Epoch 6/30\n",
            "800/800 [==============================] - 1s 685us/step - loss: 0.1189 - acc: 0.9513 - val_loss: 0.9257 - val_acc: 0.6400\n",
            "Epoch 7/30\n",
            "800/800 [==============================] - 1s 670us/step - loss: 0.1100 - acc: 0.9637 - val_loss: 0.8612 - val_acc: 0.6200\n",
            "Epoch 8/30\n",
            "800/800 [==============================] - 1s 730us/step - loss: 0.0999 - acc: 0.9625 - val_loss: 0.9175 - val_acc: 0.6350\n",
            "Epoch 9/30\n",
            "800/800 [==============================] - 1s 743us/step - loss: 0.0998 - acc: 0.9675 - val_loss: 0.8966 - val_acc: 0.5950\n",
            "Epoch 10/30\n",
            "800/800 [==============================] - 1s 730us/step - loss: 0.0981 - acc: 0.9650 - val_loss: 0.9581 - val_acc: 0.6150\n",
            "Epoch 11/30\n",
            "800/800 [==============================] - 1s 747us/step - loss: 0.1273 - acc: 0.9487 - val_loss: 0.8529 - val_acc: 0.5900\n",
            "Epoch 12/30\n",
            "800/800 [==============================] - 1s 740us/step - loss: 0.1013 - acc: 0.9637 - val_loss: 0.9206 - val_acc: 0.6100\n",
            "Epoch 13/30\n",
            "800/800 [==============================] - 1s 716us/step - loss: 0.0818 - acc: 0.9650 - val_loss: 0.9883 - val_acc: 0.6000\n",
            "Epoch 14/30\n",
            "800/800 [==============================] - 1s 720us/step - loss: 0.0889 - acc: 0.9662 - val_loss: 0.9325 - val_acc: 0.5850\n",
            "Epoch 15/30\n",
            "800/800 [==============================] - 1s 781us/step - loss: 0.0670 - acc: 0.9812 - val_loss: 1.0403 - val_acc: 0.5950\n",
            "Epoch 16/30\n",
            "800/800 [==============================] - 1s 736us/step - loss: 0.0910 - acc: 0.9688 - val_loss: 0.8575 - val_acc: 0.6200\n",
            "Epoch 17/30\n",
            "800/800 [==============================] - 1s 770us/step - loss: 0.0899 - acc: 0.9688 - val_loss: 0.9639 - val_acc: 0.6100\n",
            "Epoch 18/30\n",
            "800/800 [==============================] - 1s 727us/step - loss: 0.0860 - acc: 0.9700 - val_loss: 0.9072 - val_acc: 0.6200\n",
            "Epoch 19/30\n",
            "800/800 [==============================] - 1s 699us/step - loss: 0.0794 - acc: 0.9738 - val_loss: 0.9135 - val_acc: 0.6200\n",
            "Epoch 20/30\n",
            "800/800 [==============================] - 1s 686us/step - loss: 0.0718 - acc: 0.9800 - val_loss: 0.9514 - val_acc: 0.6200\n",
            "Epoch 21/30\n",
            "800/800 [==============================] - 1s 735us/step - loss: 0.0714 - acc: 0.9763 - val_loss: 0.9777 - val_acc: 0.6000\n",
            "Epoch 22/30\n",
            "800/800 [==============================] - 1s 718us/step - loss: 0.1074 - acc: 0.9587 - val_loss: 0.7844 - val_acc: 0.6150\n",
            "Epoch 23/30\n",
            "800/800 [==============================] - 1s 749us/step - loss: 0.0548 - acc: 0.9825 - val_loss: 0.9745 - val_acc: 0.6150\n",
            "Epoch 24/30\n",
            "800/800 [==============================] - 1s 727us/step - loss: 0.0422 - acc: 0.9788 - val_loss: 1.0671 - val_acc: 0.5900\n",
            "Epoch 25/30\n",
            "800/800 [==============================] - 1s 724us/step - loss: 0.0675 - acc: 0.9800 - val_loss: 1.0071 - val_acc: 0.6050\n",
            "Epoch 26/30\n",
            "800/800 [==============================] - 1s 718us/step - loss: 0.0594 - acc: 0.9862 - val_loss: 0.9592 - val_acc: 0.5850\n",
            "Epoch 27/30\n",
            "800/800 [==============================] - 1s 738us/step - loss: 0.0532 - acc: 0.9825 - val_loss: 0.9851 - val_acc: 0.5900\n",
            "Epoch 28/30\n",
            "800/800 [==============================] - 1s 697us/step - loss: 0.0552 - acc: 0.9838 - val_loss: 1.1130 - val_acc: 0.6100\n",
            "Epoch 29/30\n",
            "800/800 [==============================] - 1s 718us/step - loss: 0.0641 - acc: 0.9788 - val_loss: 0.9673 - val_acc: 0.5750\n",
            "Epoch 30/30\n",
            "800/800 [==============================] - 1s 730us/step - loss: 0.0539 - acc: 0.9838 - val_loss: 1.0271 - val_acc: 0.6050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLn8TDFk7R1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "0f9037b3-b226-4130-e5dc-8df07e33df6e"
      },
      "source": [
        "score, acc = model.evaluate(X_train, y_train, batch_size=batch_size)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)\n",
        "\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "# Plot the accuracy curves for training and validation \n",
        "pyplot.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "pyplot.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "legend = pyplot.legend(loc='best', shadow=True)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 0s 122us/step\n",
            "Train score: 0.009456958286464215\n",
            "Train accuracy: 1.0\n",
            "200/200 [==============================] - 0s 139us/step\n",
            "Test score: 1.0271145009994507\n",
            "Test accuracy: 0.605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD5CAYAAADY+KXfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noa6UUg7y/8wjPRuVRHSRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVkV-E7pAlvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}